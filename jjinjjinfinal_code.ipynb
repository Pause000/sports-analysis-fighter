{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d2d7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04760c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2011a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n",
      "\n",
      "==================================================\n",
      "\n",
      "â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£\n",
      "       [ì…ë ¥ê°’ ë° ì¶”ì²œ ë¶„ì„ ë¦¬í¬íŠ¸]       \n",
      "â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£\n",
      "â–¶ ì„ í˜¸ ìŠ¤íƒ€ì¼    : ì˜¤ë Œì§€í•˜ìš°ìŠ¤\n",
      "â–¶ ì‚¬ìš©ì ìœ í˜•    : ì…ë¬¸ì (Beginner)\n",
      "â–¶ ì¶”ì²œ ëŒ€ìƒ ë¦¬ê·¸ : F1\n",
      "--------------------------------------------------\n",
      "âœ¨ ì¶”ì²œ ê²°ê³¼ (ìƒìœ„ 5ê°œ íŒ€):\n",
      "1ìœ„: [ë ˆë“œë¶ˆ]\n",
      "   - ì •í•©ë„ ì ìˆ˜: -0.8768 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "-----------------------------------\n",
      "2ìœ„: [í•˜ìŠ¤]\n",
      "   - ì •í•©ë„ ì ìˆ˜: -2.5507 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "-----------------------------------\n",
      "3ìœ„: [ë§¥ë¼ë Œ]\n",
      "   - ì •í•©ë„ ì ìˆ˜: -2.8712 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "-----------------------------------\n",
      "4ìœ„: [ìœŒë¦¬ì—„ìŠ¤]\n",
      "   - ì •í•©ë„ ì ìˆ˜: -3.3908 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "-----------------------------------\n",
      "5ìœ„: [ììš°ë²„]\n",
      "   - ì •í•©ë„ ì ìˆ˜: -3.6006 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
      "-----------------------------------\n",
      "â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£â–£\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import joblib\n",
    "import warnings\n",
    "from node2vec import Node2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì•„í‹°íŒ©íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "# ---------------------------------------------------------\n",
    "DATA_DIR = r'./JSON ëª¨ìŒ'\n",
    "model_nlp = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "LEAGUE_MAP = {\n",
    "    \"Kë¦¬ê·¸\": \"K league\",\n",
    "    \"EPL\": \"EPL\",\n",
    "    \"KBO\": \"KBO\",\n",
    "    \"F1\": \"F1\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('sports_chatbot_model2.joblib')\n",
    "    final_model = artifacts['final_model']\n",
    "    pca = artifacts['pca']\n",
    "    scaler = artifacts['scaler']\n",
    "    le_team = artifacts['le_team']\n",
    "    le_league = artifacts['le_league']\n",
    "    input_features = artifacts['input_features']\n",
    "    print(\"âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ë°ì´í„° ë¡œë”© ë° N2V êµ¬ì¶•\n",
    "# ---------------------------------------------------------\n",
    "def load_teams(path):\n",
    "    teams = []\n",
    "    if not os.path.exists(path): return teams\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n",
    "                    teams.append(json.load(f))\n",
    "    return teams\n",
    "\n",
    "def build_n2v_model(teams_data):\n",
    "    G = nx.Graph()\n",
    "    for t in teams_data:\n",
    "        if 'team_name' in t: G.add_node(t['team_name'])\n",
    "    \n",
    "    for i in range(len(teams_data)):\n",
    "        for j in range(i + 1, len(teams_data)):\n",
    "            tags1 = set(teams_data[i].get('style_tags', []))\n",
    "            tags2 = set(teams_data[j].get('style_tags', []))\n",
    "            common = len(tags1.intersection(tags2))\n",
    "            if common > 0:\n",
    "                G.add_edge(teams_data[i]['team_name'], teams_data[j]['team_name'], weight=common)\n",
    "    \n",
    "    n2v = Node2Vec(G, dimensions=64, walk_length=10, num_walks=40, workers=1, quiet=True)\n",
    "    return n2v.fit(window=5, min_count=1)\n",
    "\n",
    "print(\"ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "teams_master = load_teams(DATA_DIR)\n",
    "n2v_model = build_n2v_model(teams_master)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹¤ì‹œê°„ ì ìˆ˜ ê³„ì‚° (N2V ìœ ì‚¬ë„ ë°˜ì˜)\n",
    "# ---------------------------------------------------------\n",
    "def get_scores_strict(query, anchor_name, candidate):\n",
    "    # sbert_score\n",
    "    cand_tags = \" \".join(candidate.get('style_tags', []))\n",
    "    embs = model_nlp.encode([query, cand_tags])\n",
    "    s_sem = cosine_similarity([embs[0]], [embs[1]])[0][0]\n",
    "\n",
    "    # n2v_score: ì‘ì› íŒ€ì´ ìˆì„ ë•Œë§Œ ëª¨ë¸ì—ì„œ ê´€ê³„ ì ìˆ˜ ì‚°ì¶œ\n",
    "    s_rel = 0.5\n",
    "    if anchor_name and anchor_name in n2v_model.wv and candidate['team_name'] in n2v_model.wv:\n",
    "        s_rel = n2v_model.wv.similarity(anchor_name, candidate['team_name'])\n",
    "\n",
    "    # vector_score (7ëŒ€ ì§€í‘œ ê¸°ë°˜)\n",
    "    ts = candidate.get('scores', {})\n",
    "    metrics = ['strength', 'money', 'star_power', 'attack_style', 'underdog_feel', 'fan_passion', 'tradition']\n",
    "    t_vec = np.array([ts.get(m, 10) for m in metrics])\n",
    "    s_vec = cosine_similarity(np.array([10]*7).reshape(1, -1), t_vec.reshape(1, -1))[0][0]\n",
    "    \n",
    "    return s_sem, s_rel, s_vec\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì¶”ì²œ ì„œë¹„ìŠ¤ (ë©”ì¸ ë¡œì§)\n",
    "# ---------------------------------------------------------\n",
    "def recommend_service(query, user_type, support_team, target_league):\n",
    "    json_league_name = LEAGUE_MAP.get(target_league, target_league)\n",
    "    \n",
    "    candidates = [t for t in teams_master if t.get('league', '').lower() == json_league_name.lower()]\n",
    "    if not candidates: return f\"'{target_league}'ì— í•´ë‹¹í•˜ëŠ” íŒ€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    query_pca = pca.transform(model_nlp.encode([query]))[0]\n",
    "    pca_cols = [\"ì˜ë„_íŒ¬ë¤ì •ì²´ì„±\", \"ì˜ë„_ìŠ¤íƒ€ì„±ê³¼ê°•í•¨\", \"ì˜ë„_ëª…ë¬¸ê³¼ê¸°ì \", \"ì˜ë„_ë¹„ì£¼ì–¼ê³¼ë§¤ë ¥\", \"ì˜ë„_ìë³¸ê³¼ì§€ë°°ë ¥\"]\n",
    "\n",
    "    rows = []\n",
    "    for cand in candidates:\n",
    "        s_sem, s_rel, s_vec = get_scores_strict(query, support_team, cand)\n",
    "        row = {\n",
    "            'matching_team': cand['team_name'],\n",
    "            'user_type': int(user_type),\n",
    "            'recommend_league': json_league_name,\n",
    "            'sbert_score': s_sem,\n",
    "            'n2v_score': s_rel,\n",
    "            'vector_score': s_vec\n",
    "        }\n",
    "        for i, col in enumerate(pca_cols): row[col] = query_pca[i]\n",
    "        rows.append(row)\n",
    "\n",
    "    df_inf = pd.DataFrame(rows)\n",
    "    df_inf['recommend_league_enc'] = le_league.transform(df_inf['recommend_league'].astype(str))\n",
    "    \n",
    "    score_cols = ['sbert_score', 'n2v_score', 'vector_score']\n",
    "    scaled = scaler.transform(df_inf[score_cols])\n",
    "    df_inf['sbert_score_mm'], df_inf['n2v_score_mm'], df_inf['vector_score_mm'] = scaled[:,0], scaled[:,1], scaled[:,2]\n",
    "\n",
    "    X_input = df_inf[input_features]\n",
    "    cat_cols = [c for c in [\"user_type\", \"recommend_league_enc\"] if c in input_features]\n",
    "    for c in cat_cols:\n",
    "        X_input[c] = X_input[c].astype('category')\n",
    "\n",
    "    df_inf['predict_score'] = final_model.predict(X_input)\n",
    "    return df_inf.sort_values(by='predict_score', ascending=False)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. ì‹¤í–‰ ë° ì…ë ¥ê°’ ì¶œë ¥\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "user_q = input(\"ğŸ’¬ ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ íŒ€ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”? (ì˜ˆ: ëˆì€ ì—†ì§€ë§Œ ì—´ì •ì ì¸ íŒ€): \")\n",
    "ut_raw = input(\"ğŸ’¬ ìŠ¤í¬ì¸  íŒ¬ì´ì‹ ê°€ìš”? (1:íŒ¬, 0:ì´ˆë³´): \")\n",
    "\n",
    "my_team = None\n",
    "if ut_raw == '1':\n",
    "    my_team = input(\"ğŸ’¬ í˜„ì¬ ì‘ì›í•˜ê³  ê³„ì‹  íŒ€ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: \")\n",
    "\n",
    "target_raw = input(\"ğŸ’¬ ì–´ë–¤ ë¦¬ê·¸ì˜ íŒ€ì„ ì¶”ì²œë°›ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (EPL/Kë¦¬ê·¸/KBO/F1): \")\n",
    "\n",
    "# ì¶”ì²œ ì‹¤í–‰\n",
    "res = recommend_service(user_q, ut_raw, my_team, target_raw)\n",
    "\n",
    "# ê²°ê³¼ ëŒ€ì‹œë³´ë“œ ì¶œë ¥\n",
    "print(\"\\n\" + \"â–£\"*25)\n",
    "print(\"       [ì…ë ¥ê°’ ë° ì¶”ì²œ ë¶„ì„ ë¦¬í¬íŠ¸]       \")\n",
    "print(\"â–£\"*25)\n",
    "print(f\"â–¶ ì„ í˜¸ ìŠ¤íƒ€ì¼    : {user_q}\")\n",
    "print(f\"â–¶ ì‚¬ìš©ì ìœ í˜•    : {'ê¸°ì¡´ íŒ¬ (Fan)' if ut_raw == '1' else 'ì…ë¬¸ì (Beginner)'}\")\n",
    "if ut_raw == '1':\n",
    "    print(f\"â–¶ ê¸°ì¡´ ì‘ì›íŒ€    : {my_team}\")\n",
    "print(f\"â–¶ ì¶”ì²œ ëŒ€ìƒ ë¦¬ê·¸ : {target_raw}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if isinstance(res, str):\n",
    "    print(f\"âš ï¸ ê²°ê³¼: {res}\")\n",
    "else:\n",
    "    print(f\"âœ¨ ì¶”ì²œ ê²°ê³¼ (ìƒìœ„ 5ê°œ íŒ€):\")\n",
    "    # itertuples()ë¥¼ í†µí•´ ê²°ê³¼ í–‰ë“¤ì„ ìˆœíšŒí•©ë‹ˆë‹¤.\n",
    "    for i, row in enumerate(res.head(5).itertuples(), 1):\n",
    "        print(f\"{i}ìœ„: [{row.matching_team}]\")\n",
    "        print(f\"   - ì •í•©ë„ ì ìˆ˜: {row.predict_score:.4f} (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\")\n",
    "        # ì‘ì›íŒ€ì´ ìˆì„ ë•Œë§Œ n2v_scoreì˜ ì˜ë¯¸ê°€ í½ë‹ˆë‹¤.\n",
    "        if ut_raw == '1':\n",
    "            print(f\"   - ê´€ê³„ ìœ ì‚¬ë„(n2v): {row.n2v_score:.4f}\")\n",
    "        print(\"-\" * 35)\n",
    "\n",
    "print(\"â–£\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n",
      "\n",
      "==================================================\n",
      "\n",
      "âœ¨ ë‹¹ì‹ ì„ ìœ„í•œ 'K LEAGUE' ë¦¬ê·¸ 5:5 í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìˆœìœ„ì…ë‹ˆë‹¤:\n",
      "â­ 1ìœ„: FC ì„œìš¸\n",
      "    [ìµœì¢… ì ìˆ˜: 0.6819] (ìˆ˜ë™: 0.5396 / ëª¨ë¸: 1.2509)\n",
      "â­ 2ìœ„: ì „ë¶ í˜„ëŒ€ ëª¨í„°ìŠ¤\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5291] (ìˆ˜ë™: 0.5697 / ëª¨ë¸: 0.3670)\n",
      "â­ 3ìœ„: ì¸ì²œ ìœ ë‚˜ì´í‹°ë“œ\n",
      "    [ìµœì¢… ì ìˆ˜: 0.4166] (ìˆ˜ë™: 0.5724 / ëª¨ë¸: -0.2064)\n",
      "   4ìœ„: ê´‘ì£¼FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.3756] (ìˆ˜ë™: 0.5449 / ëª¨ë¸: -0.3016)\n",
      "   5ìœ„: ëŒ€ì „ í•˜ë‚˜ ì‹œí‹°ì¦Œ\n",
      "    [ìµœì¢… ì ìˆ˜: 0.3589] (ìˆ˜ë™: 0.5574 / ëª¨ë¸: -0.4350)\n",
      "   6ìœ„: ìˆ˜ì› ì‚¼ì„± ë¸”ë£¨ìœ™ì¦ˆ\n",
      "    [ìµœì¢… ì ìˆ˜: 0.2261] (ìˆ˜ë™: 0.5739 / ëª¨ë¸: -1.1652)\n",
      "   7ìœ„: ëŒ€êµ¬FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.2087] (ìˆ˜ë™: 0.5389 / ëª¨ë¸: -1.1123)\n",
      "   8ìœ„: ê°•ì›FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.1913] (ìˆ˜ë™: 0.5655 / ëª¨ë¸: -1.3054)\n",
      "   9ìœ„: ì œì£¼ SK FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.1688] (ìˆ˜ë™: 0.5238 / ëª¨ë¸: -1.2513)\n",
      "   10ìœ„: ìš¸ì‚° HD FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.1256] (ìˆ˜ë™: 0.5370 / ëª¨ë¸: -1.5197)\n",
      "   11ìœ„: í¬í•­ ìŠ¤í‹¸ëŸ¬ìŠ¤\n",
      "    [ìµœì¢… ì ìˆ˜: 0.1020] (ìˆ˜ë™: 0.5595 / ëª¨ë¸: -1.7282)\n",
      "   12ìœ„: FCì•ˆì–‘\n",
      "    [ìµœì¢… ì ìˆ˜: -0.0366] (ìˆ˜ë™: 0.5635 / ëª¨ë¸: -2.4370)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import joblib\n",
    "import warnings\n",
    "from node2vec import Node2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì•„í‹°íŒ©íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "# ---------------------------------------------------------\n",
    "DATA_DIR = r'./JSON ëª¨ìŒ'\n",
    "model_nlp = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# [ì¶”ê°€] score.pyì˜ ë¡œì§ ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.4, 0.2\n",
    "\n",
    "LEAGUE_MAP = {\n",
    "    \"Kë¦¬ê·¸\": \"K league\",\n",
    "    \"EPL\": \"EPL\",\n",
    "    \"KBO\": \"KBO\",\n",
    "    \"F1\": \"F1\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('sports_chatbot_model2.joblib')\n",
    "    final_model = artifacts['final_model']\n",
    "    pca = artifacts['pca']\n",
    "    scaler = artifacts['scaler']\n",
    "    le_team = artifacts['le_team']\n",
    "    le_league = artifacts['le_league']\n",
    "    input_features = artifacts['input_features']\n",
    "    print(\"âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ë°ì´í„° ë¡œë”© ë° N2V êµ¬ì¶• (ê¸°ì¡´ ìœ ì§€)\n",
    "# ---------------------------------------------------------\n",
    "def load_teams(path):\n",
    "    teams = []\n",
    "    if not os.path.exists(path): return teams\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n",
    "                    teams.append(json.load(f))\n",
    "    return teams\n",
    "\n",
    "def build_n2v_model(teams_data):\n",
    "    G = nx.Graph()\n",
    "    for t in teams_data:\n",
    "        if 'team_name' in t: G.add_node(t['team_name'])\n",
    "    \n",
    "    for i in range(len(teams_data)):\n",
    "        for j in range(i + 1, len(teams_data)):\n",
    "            tags1 = set(teams_data[i].get('style_tags', []))\n",
    "            tags2 = set(teams_data[j].get('style_tags', []))\n",
    "            common = len(tags1.intersection(tags2))\n",
    "            if common > 0:\n",
    "                G.add_edge(teams_data[i]['team_name'], teams_data[j]['team_name'], weight=common)\n",
    "    \n",
    "    n2v = Node2Vec(G, dimensions=64, walk_length=10, num_walks=40, workers=1, quiet=True)\n",
    "    return n2v.fit(window=5, min_count=1)\n",
    "\n",
    "print(\"ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "teams_master = load_teams(DATA_DIR)\n",
    "n2v_model = build_n2v_model(teams_master)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹¤ì‹œê°„ ì ìˆ˜ ê³„ì‚° (anchor_name ë°˜ì˜)\n",
    "# ---------------------------------------------------------\n",
    "def get_scores_strict(query, anchor_name, candidate):\n",
    "    # sbert_score\n",
    "    cand_tags = \" \".join(candidate.get('style_tags', []))\n",
    "    embs = model_nlp.encode([query, cand_tags])\n",
    "    s_sem = cosine_similarity([embs[0]], [embs[1]])[0][0]\n",
    "\n",
    "    # n2v_score\n",
    "    s_rel = 0.5\n",
    "    if anchor_name and anchor_name in n2v_model.wv and candidate['team_name'] in n2v_model.wv:\n",
    "        s_rel = n2v_model.wv.similarity(anchor_name, candidate['team_name'])\n",
    "\n",
    "    # vector_score\n",
    "    ts = candidate.get('scores', {})\n",
    "    metrics = ['strength', 'money', 'star_power', 'attack_style', 'underdog_feel', 'fan_passion', 'tradition']\n",
    "    t_vec = np.array([ts.get(m, 10) for m in metrics])\n",
    "    # ê¸°ì¤€ ë²¡í„°ì™€ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ëª¨ë‘ 10ì ì¸ ì´ìƒì ì¸ íŒ€ ê¸°ì¤€)\n",
    "    s_vec = cosine_similarity(np.array([10]*7).reshape(1, -1), t_vec.reshape(1, -1))[0][0]\n",
    "    \n",
    "    return s_sem, s_rel, s_vec\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì¶”ì²œ ì„œë¹„ìŠ¤ (5:5 í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§ ì ìš©)\n",
    "# ---------------------------------------------------------\n",
    "def recommend_service(query, user_type, support_team, target_league):\n",
    "    json_league_name = LEAGUE_MAP.get(target_league, target_league)\n",
    "    \n",
    "    candidates = [t for t in teams_master if t.get('league', '').lower() == json_league_name.lower()]\n",
    "    if not candidates: return f\"'{target_league}'ì— í•´ë‹¹í•˜ëŠ” íŒ€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    query_pca = pca.transform(model_nlp.encode([query]))[0]\n",
    "    pca_cols = [\"ì˜ë„_íŒ¬ë¤ì •ì²´ì„±\", \"ì˜ë„_ìŠ¤íƒ€ì„±ê³¼ê°•í•¨\", \"ì˜ë„_ëª…ë¬¸ê³¼ê¸°ì \", \"ì˜ë„_ë¹„ì£¼ì–¼ê³¼ë§¤ë ¥\", \"ì˜ë„_ìë³¸ê³¼ì§€ë°°ë ¥\"]\n",
    "\n",
    "    rows = []\n",
    "    for cand in candidates:\n",
    "        s_sem, s_rel, s_vec = get_scores_strict(query, support_team, cand)\n",
    "        \n",
    "        # [í•µì‹¬] score.py ë°©ì‹ì˜ ìˆ˜ë™ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°\n",
    "        manual_match_score = (s_sem * ALPHA) + (s_rel * BETA) + (s_vec * GAMMA)\n",
    "\n",
    "        row = {\n",
    "            'matching_team': cand['team_name'],\n",
    "            'user_type': int(user_type),\n",
    "            'recommend_league': json_league_name,\n",
    "            'sbert_score': s_sem,\n",
    "            'n2v_score': s_rel,\n",
    "            'vector_score': s_vec,\n",
    "            'manual_match_score': manual_match_score  # ìˆ˜ë™ ì ìˆ˜ ì €ì¥\n",
    "        }\n",
    "        for i, col in enumerate(pca_cols): row[col] = query_pca[i]\n",
    "        rows.append(row)\n",
    "\n",
    "    df_inf = pd.DataFrame(rows)\n",
    "    df_inf['recommend_league_enc'] = le_league.transform(df_inf['recommend_league'].astype(str))\n",
    "    \n",
    "    # ëª¨ë¸ ì…ë ¥ìš© ìŠ¤ì¼€ì¼ë§\n",
    "    score_cols = ['sbert_score', 'n2v_score', 'vector_score']\n",
    "    scaled = scaler.transform(df_inf[score_cols])\n",
    "    df_inf['sbert_score_mm'], df_inf['n2v_score_mm'], df_inf['vector_score_mm'] = scaled[:,0], scaled[:,1], scaled[:,2]\n",
    "\n",
    "    # ëª¨ë¸ ì˜ˆì¸¡\n",
    "    X_input = df_inf[input_features]\n",
    "    cat_cols = [c for c in [\"user_type\", \"recommend_league_enc\"] if c in input_features]\n",
    "    for c in cat_cols:\n",
    "        X_input[c] = X_input[c].astype('category')\n",
    "\n",
    "    df_inf['predict_score'] = final_model.predict(X_input)\n",
    "\n",
    "    # [í•µì‹¬] 5:5 ìµœì¢… ì ìˆ˜ í•©ì‚° (Hybrid Score)\n",
    "    # ë‘ ì ìˆ˜ì˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ê·œí™”ë¥¼ ê³ ë ¤í•  ìˆ˜ ìˆìœ¼ë‚˜, ê¸°ë³¸ì ìœ¼ë¡œ 5:5 ê²°í•© ìˆ˜í–‰\n",
    "    df_inf['final_hybrid_score'] = (df_inf['manual_match_score'] * 0.8) + (df_inf['predict_score'] * 0.2)\n",
    "\n",
    "    return df_inf.sort_values(by='final_hybrid_score', ascending=False)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. ì‹¤í–‰ë¶€ (ê²°ê³¼ ì¶œë ¥ ìˆ˜ì •)\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "user_q = input(\"ğŸ’¬ ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ íŒ€ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?: \")\n",
    "ut = input(\"ğŸ’¬ ìŠ¤í¬ì¸  íŒ¬ì´ì‹ ê°€ìš”? (1:íŒ¬, 0:ì´ˆë³´): \")\n",
    "\n",
    "my_team = None\n",
    "if ut == '1':\n",
    "    print(f\"í˜„ì¬ ë“±ë¡ëœ íŒ€ ì˜ˆì‹œ: {', '.join([t['team_name'] for t in teams_master[:5]])} ë“±\")\n",
    "    my_team = input(\"ğŸ’¬ í˜„ì¬ ì‘ì›í•˜ê³  ê³„ì‹  íŒ€ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: \")\n",
    "\n",
    "target = input(\"ğŸ’¬ ì–´ë–¤ ë¦¬ê·¸ì˜ íŒ€ì„ ì¶”ì²œë°›ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (EPL/Kë¦¬ê·¸/KBO/F1): \")\n",
    "\n",
    "res = recommend_service(user_q, ut, my_team, target)\n",
    "\n",
    "if isinstance(res, str):\n",
    "    print(f\"\\nâš ï¸ {res}\")\n",
    "else:\n",
    "    print(f\"\\nâœ¨ ë‹¹ì‹ ì„ ìœ„í•œ '{target}' ë¦¬ê·¸ 5:5 í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìˆœìœ„ì…ë‹ˆë‹¤:\")\n",
    "    for i, row in enumerate(res.itertuples(), 1):\n",
    "        star = \"â­\" if i <= 3 else \"  \"\n",
    "        print(f\"{star} {i}ìœ„: {row.matching_team}\")\n",
    "        print(f\"    [ìµœì¢… ì ìˆ˜: {row.final_hybrid_score:.4f}] (ìˆ˜ë™: {row.manual_match_score:.4f} / ëª¨ë¸: {row.predict_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9977cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n",
      "\n",
      "==================================================\n",
      "\n",
      "âœ¨ ë‹¹ì‹ ì„ ìœ„í•œ 'K LEAGUE' ë¦¬ê·¸ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìˆœìœ„ì…ë‹ˆë‹¤:\n",
      "â­ 1ìœ„: FCì•ˆì–‘\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5995] (ìˆ˜ë™: 0.6010 / ëª¨ë¸: -0.9348)\n",
      "â­ 2ìœ„: ëŒ€ì „ í•˜ë‚˜ ì‹œí‹°ì¦Œ\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5612] (ìˆ˜ë™: 0.5627 / ëª¨ë¸: -0.8822)\n",
      "â­ 3ìœ„: ì œì£¼ SK FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5312] (ìˆ˜ë™: 0.5335 / ëª¨ë¸: -1.7629)\n",
      "   4ìœ„: ìš¸ì‚° HD FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5288] (ìˆ˜ë™: 0.5308 / ëª¨ë¸: -1.3829)\n",
      "   5ìœ„: ê´‘ì£¼FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5199] (ìˆ˜ë™: 0.5210 / ëª¨ë¸: -0.5605)\n",
      "   6ìœ„: FC ì„œìš¸\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5002] (ìˆ˜ë™: 0.5007 / ëª¨ë¸: 0.0304)\n",
      "   7ìœ„: ì „ë¶ í˜„ëŒ€ ëª¨í„°ìŠ¤\n",
      "    [ìµœì¢… ì ìˆ˜: 0.5002] (ìˆ˜ë™: 0.5019 / ëª¨ë¸: -1.2189)\n",
      "   8ìœ„: ê°•ì›FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.4953] (ìˆ˜ë™: 0.4975 / ëª¨ë¸: -1.6154)\n",
      "   9ìœ„: ì¸ì²œ ìœ ë‚˜ì´í‹°ë“œ\n",
      "    [ìµœì¢… ì ìˆ˜: 0.4775] (ìˆ˜ë™: 0.4808 / ëª¨ë¸: -2.7676)\n",
      "   10ìœ„: ìˆ˜ì› ì‚¼ì„± ë¸”ë£¨ìœ™ì¦ˆ\n",
      "    [ìµœì¢… ì ìˆ˜: 0.4758] (ìˆ˜ë™: 0.4788 / ëª¨ë¸: -2.5899)\n",
      "   11ìœ„: í¬í•­ ìŠ¤í‹¸ëŸ¬ìŠ¤\n",
      "    [ìµœì¢… ì ìˆ˜: 0.4748] (ìˆ˜ë™: 0.4778 / ëª¨ë¸: -2.5899)\n",
      "   12ìœ„: ëŒ€êµ¬FC\n",
      "    [ìµœì¢… ì ìˆ˜: 0.4724] (ìˆ˜ë™: 0.4754 / ëª¨ë¸: -2.5072)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import joblib\n",
    "import warnings\n",
    "from node2vec import Node2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì•„í‹°íŒ©íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "# ---------------------------------------------------------\n",
    "DATA_DIR = r'./JSON ëª¨ìŒ'\n",
    "model_nlp = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# score.pyì˜ ë¡œì§ ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.4, 0.2\n",
    "\n",
    "LEAGUE_MAP = {\n",
    "    \"Kë¦¬ê·¸\": \"K league\",\n",
    "    \"EPL\": \"EPL\",\n",
    "    \"KBO\": \"KBO\",\n",
    "    \"F1\": \"F1\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('sports_chatbot_model2.joblib')\n",
    "    final_model = artifacts['final_model']\n",
    "    pca = artifacts['pca']\n",
    "    scaler = artifacts['scaler']\n",
    "    le_team = artifacts['le_team']\n",
    "    le_league = artifacts['le_league']\n",
    "    input_features = artifacts['input_features']\n",
    "    print(\"âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ë°ì´í„° ë¡œë”© ë° N2V êµ¬ì¶•\n",
    "# ---------------------------------------------------------\n",
    "def load_teams(path):\n",
    "    teams = []\n",
    "    if not os.path.exists(path): return teams\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n",
    "                    teams.append(json.load(f))\n",
    "    return teams\n",
    "\n",
    "def build_n2v_model(teams_data):\n",
    "    G = nx.Graph()\n",
    "    for t in teams_data:\n",
    "        if 'team_name' in t: G.add_node(t['team_name'])\n",
    "    \n",
    "    for i in range(len(teams_data)):\n",
    "        for j in range(i + 1, len(teams_data)):\n",
    "            tags1 = set(teams_data[i].get('style_tags', []))\n",
    "            tags2 = set(teams_data[j].get('style_tags', []))\n",
    "            common = len(tags1.intersection(tags2))\n",
    "            if common > 0:\n",
    "                G.add_edge(teams_data[i]['team_name'], teams_data[j]['team_name'], weight=common)\n",
    "    \n",
    "    n2v = Node2Vec(G, dimensions=64, walk_length=10, num_walks=40, workers=1, quiet=True)\n",
    "    return n2v.fit(window=5, min_count=1)\n",
    "\n",
    "print(\"ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "teams_master = load_teams(DATA_DIR)\n",
    "n2v_model = build_n2v_model(teams_master)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹¤ì‹œê°„ ì ìˆ˜ ê³„ì‚° (ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§ ì ìš© ë²„ì „)\n",
    "# ---------------------------------------------------------\n",
    "def get_scores_strict(query, anchor_name, candidate):\n",
    "    # (1) sbert_score\n",
    "    cand_tags = \" \".join(candidate.get('style_tags', []))\n",
    "    embs = model_nlp.encode([query, cand_tags])\n",
    "    s_sem = cosine_similarity([embs[0]], [embs[1]])[0][0]\n",
    "\n",
    "    # (2) n2v_score\n",
    "    s_rel = 0.5\n",
    "    if anchor_name and anchor_name in n2v_model.wv and candidate['team_name'] in n2v_model.wv:\n",
    "        s_rel = n2v_model.wv.similarity(anchor_name, candidate['team_name'])\n",
    "\n",
    "    # (3) vector_score [ë¦¬ë”ë‹˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§ 100% ì ìš©]\n",
    "    ts = candidate.get('scores', {})\n",
    "    metrics = ['strength', 'money', 'star_power', 'attack_style', 'underdog_feel', 'fan_passion', 'tradition']\n",
    "    t_vec = np.array([ts.get(m, 10) for m in metrics])\n",
    "    \n",
    "    target_vec = np.array([10]*7)\n",
    "    s_multiplier = 1.0\n",
    "\n",
    "    # --- ìš”ì²­í•˜ì‹  ì‹œë‚˜ë¦¬ì˜¤ ì¡°ê±´ë¬¸ ì‹œì‘ ---\n",
    "    if any(k in query for k in [\"ì–¸ë”ë…\", \"ê¸°ì \", \"ì €ë¹„ìš©\", \"ë¨¸ë‹ˆë³¼\", \"íš¨ìœ¨\", \"ê°€ì„±ë¹„\"]):\n",
    "        target_vec[4] = 50\n",
    "        if ts.get('money', 10) >= 16: s_multiplier = 0.3\n",
    "        elif ts.get('money', 10) <= 8: s_multiplier = 1.5\n",
    "    elif any(k in query for k in [\"ê°•í•œ\", \"ì••ë„ì \", \"ìµœê°•\", \"ìš°ìŠ¹\", \"ë¶€ì\"]):\n",
    "        target_vec[0], target_vec[1] = 40, 40\n",
    "        if ts.get('strength', 10) < 12: s_multiplier = 0.4\n",
    "    elif any(k in query for k in [\"ë¯¸ë‚¨\", \"ì˜ìƒê¸´\", \"ë¹„ì£¼ì–¼\", \"ì–¼êµ´\", \"ì…ë•\"]):\n",
    "        target_vec[2] = 50\n",
    "        if ts.get('star_power', 10) < 12: s_multiplier = 0.4\n",
    "    elif any(k in query for k in [\"ì „í†µ\", \"ëª…ë¬¸\", \"ì—­ì‚¬\", \"ì—°ê³ ì§€\", \"ìë¶€ì‹¬\"]):\n",
    "        target_vec[6], target_vec[5] = 40, 40\n",
    "        if ts.get('tradition', 10) < 10: s_multiplier = 0.5\n",
    "    elif any(k in query for k in [\"ê³µê²©\", \"í™”ëˆ\", \"ë“ì \", \"í™ˆëŸ°\", \"ì¶”ì›”\", \"ì‹œì›ì‹œì›\"]):\n",
    "        target_vec[3] = 50\n",
    "        if ts.get('attack_style', 10) < 12: s_multiplier = 0.5\n",
    "    elif any(k in query for k in [\"ìˆ˜ë¹„\", \"ë‹¨ë‹¨í•œ\", \"ì‹¤ë¦¬\", \"ì—­ìŠµ\", \"ì§ˆì‹\"]):\n",
    "        target_vec[4], target_vec[0] = 30, 30\n",
    "        if ts.get('attack_style', 10) > 15: s_multiplier = 0.5\n",
    "    # --- ìš”ì²­í•˜ì‹  ì‹œë‚˜ë¦¬ì˜¤ ì¡°ê±´ë¬¸ ë ---\n",
    "    \n",
    "    # ìµœì¢… ë²¡í„° ì ìˆ˜ ê³„ì‚°\n",
    "    s_vec = cosine_similarity(target_vec.reshape(1, -1), t_vec.reshape(1, -1))[0][0]\n",
    "    s_vec = s_vec * s_multiplier\n",
    "    \n",
    "    return s_sem, s_rel, s_vec\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì¶”ì²œ ì„œë¹„ìŠ¤ (í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§)\n",
    "# ---------------------------------------------------------\n",
    "def recommend_service(query, user_type, support_team, target_league):\n",
    "    json_league_name = LEAGUE_MAP.get(target_league, target_league)\n",
    "    \n",
    "    candidates = [t for t in teams_master if t.get('league', '').lower() == json_league_name.lower()]\n",
    "    if not candidates: return f\"'{target_league}'ì— í•´ë‹¹í•˜ëŠ” íŒ€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    query_pca = pca.transform(model_nlp.encode([query]))[0]\n",
    "    pca_cols = [\"ì˜ë„_íŒ¬ë¤ì •ì²´ì„±\", \"ì˜ë„_ìŠ¤íƒ€ì„±ê³¼ê°•í•¨\", \"ì˜ë„_ëª…ë¬¸ê³¼ê¸°ì \", \"ì˜ë„_ë¹„ì£¼ì–¼ê³¼ë§¤ë ¥\", \"ì˜ë„_ìë³¸ê³¼ì§€ë°°ë ¥\"]\n",
    "\n",
    "    rows = []\n",
    "    for cand in candidates:\n",
    "        s_sem, s_rel, s_vec = get_scores_strict(query, support_team, cand)\n",
    "        \n",
    "        # ìˆ˜ë™ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (score.py ë°©ì‹)\n",
    "        manual_match_score = (s_sem * ALPHA) + (s_rel * BETA) + (s_vec * GAMMA)\n",
    "\n",
    "        row = {\n",
    "            'matching_team': cand['team_name'],\n",
    "            'user_type': int(user_type),\n",
    "            'recommend_league': json_league_name,\n",
    "            'sbert_score': s_sem,\n",
    "            'n2v_score': s_rel,\n",
    "            'vector_score': s_vec,\n",
    "            'manual_match_score': manual_match_score\n",
    "        }\n",
    "        for i, col in enumerate(pca_cols): row[col] = query_pca[i]\n",
    "        rows.append(row)\n",
    "\n",
    "    df_inf = pd.DataFrame(rows)\n",
    "    df_inf['recommend_league_enc'] = le_league.transform(df_inf['recommend_league'].astype(str))\n",
    "    \n",
    "    # ìŠ¤ì¼€ì¼ë§ ë° ëª¨ë¸ ì˜ˆì¸¡\n",
    "    score_cols = ['sbert_score', 'n2v_score', 'vector_score']\n",
    "    scaled = scaler.transform(df_inf[score_cols])\n",
    "    df_inf['sbert_score_mm'], df_inf['n2v_score_mm'], df_inf['vector_score_mm'] = scaled[:,0], scaled[:,1], scaled[:,2]\n",
    "\n",
    "    X_input = df_inf[input_features]\n",
    "    cat_cols = [c for c in [\"user_type\", \"recommend_league_enc\"] if c in input_features]\n",
    "    for c in cat_cols: X_input[c] = X_input[c].astype('category')\n",
    "\n",
    "    df_inf['predict_score'] = final_model.predict(X_input)\n",
    "\n",
    "    # ìµœì¢… 8:2 í•˜ì´ë¸Œë¦¬ë“œ ê²°í•©\n",
    "    df_inf['final_hybrid_score'] = (df_inf['manual_match_score'] * 0.85) + (df_inf['predict_score'] * 0.15)\n",
    "\n",
    "    return df_inf.sort_values(by='final_hybrid_score', ascending=False)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. ì‹¤í–‰ë¶€\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "user_q = input(\"ğŸ’¬ ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ íŒ€ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?: \")\n",
    "ut = input(\"ğŸ’¬ ìŠ¤í¬ì¸  íŒ¬ì´ì‹ ê°€ìš”? (1:íŒ¬, 0:ì´ˆë³´): \")\n",
    "\n",
    "my_team = None\n",
    "if ut == '1':\n",
    "    print(f\"í˜„ì¬ ë“±ë¡ëœ íŒ€ ì˜ˆì‹œ: {', '.join([t['team_name'] for t in teams_master[:5]])} ë“±\")\n",
    "    my_team = input(\"ğŸ’¬ í˜„ì¬ ì‘ì›í•˜ê³  ê³„ì‹  íŒ€ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: \")\n",
    "\n",
    "target = input(\"ğŸ’¬ ì–´ë–¤ ë¦¬ê·¸ì˜ íŒ€ì„ ì¶”ì²œë°›ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (EPL/Kë¦¬ê·¸/KBO/F1): \")\n",
    "\n",
    "res = recommend_service(user_q, ut, my_team, target)\n",
    "\n",
    "if isinstance(res, str):\n",
    "    print(f\"\\nâš ï¸ {res}\")\n",
    "else:\n",
    "    print(f\"\\nâœ¨ ë‹¹ì‹ ì„ ìœ„í•œ '{target}' ë¦¬ê·¸ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìˆœìœ„ì…ë‹ˆë‹¤:\")\n",
    "    for i, row in enumerate(res.itertuples(), 1):\n",
    "        star = \"â­\" if i <= 3 else \"  \"\n",
    "        print(f\"{star} {i}ìœ„: {row.matching_team}\")\n",
    "        print(f\"    [ìµœì¢… ì ìˆ˜: {row.final_hybrid_score:.4f}] (ìˆ˜ë™: {row.manual_match_score:.4f} / ëª¨ë¸: {row.predict_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e071e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” SBERT ëª¨ë¸(KR-SBERT) ë¡œë”© ì¤‘...\n",
      "ğŸ” PCA ì¸ì½”ë” ëª¨ë¸(ko-sroberta) ë¡œë”© ì¤‘...\n",
      "âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸš€ íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘...\n",
      "\n",
      "==================================================\n",
      "\n",
      "âœ¨ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ê²°ê³¼:\n",
      "1ìœ„: ì• ìŠ¤í„´ ë§ˆí‹´ [ì¢…í•©: 0.1830 (ì‹œë‚˜ë¦¬ì˜¤: 0.3682 / AI: -0.5578)]\n",
      "2ìœ„: ë©”ë¥´ì„¸ë°ìŠ¤ [ì¢…í•©: 0.0377 (ì‹œë‚˜ë¦¬ì˜¤: 0.3865 / AI: -1.3575)]\n",
      "3ìœ„: í˜ë¼ë¦¬ [ì¢…í•©: 0.0324 (ì‹œë‚˜ë¦¬ì˜¤: 0.4584 / AI: -1.6714)]\n",
      "4ìœ„: ë ˆì´ì‹± ë¶ˆìŠ¤ [ì¢…í•©: 0.0273 (ì‹œë‚˜ë¦¬ì˜¤: 0.5012 / AI: -1.8683)]\n",
      "5ìœ„: ë ˆë“œë¶ˆ [ì¢…í•©: 0.0254 (ì‹œë‚˜ë¦¬ì˜¤: 0.5073 / AI: -1.9022)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import joblib\n",
    "import warnings\n",
    "from node2vec import Node2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ëª¨ë¸ ë° í™˜ê²½ ì„¤ì • (ì´ì›í™” ë¡œë”©)\n",
    "# ---------------------------------------------------------\n",
    "DATA_DIR = r'./JSON ëª¨ìŒ'\n",
    "\n",
    "# [ëª¨ë¸ 1] s_sem(ì˜ë¯¸ ìœ ì‚¬ë„) ì „ìš©: ê¸°ì¡´ SBERT\n",
    "print(\"ğŸ” SBERT ëª¨ë¸(KR-SBERT) ë¡œë”© ì¤‘...\")\n",
    "model_sbert = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# [ëª¨ë¸ 2] PCA(ì˜ë„ ë¶„ì„) ì „ìš©: ë¬¸ë§¥ ì´í•´ íŠ¹í™” ëª¨ë¸\n",
    "print(\"ğŸ” PCA ì¸ì½”ë” ëª¨ë¸(ko-sroberta) ë¡œë”© ì¤‘...\")\n",
    "model_pca_encoder = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
    "\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.4, 0.2\n",
    "\n",
    "LEAGUE_MAP = {\n",
    "    \"Kë¦¬ê·¸\": \"K league\", \"EPL\": \"EPL\", \"KBO\": \"KBO\", \"F1\": \"F1\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('sports_chatbot_model2.joblib')\n",
    "    final_model = artifacts['final_model']\n",
    "    pca = artifacts['pca']\n",
    "    scaler = artifacts['scaler']\n",
    "    le_league = artifacts['le_league']\n",
    "    input_features = artifacts['input_features']\n",
    "    print(\"âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ë°ì´í„° ë¡œë”© ë° N2V êµ¬ì¶• (ê¸°ì¡´ ìœ ì§€)\n",
    "# ---------------------------------------------------------\n",
    "def load_teams(path):\n",
    "    teams = []\n",
    "    if not os.path.exists(path): return teams\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n",
    "                    teams.append(json.load(f))\n",
    "    return teams\n",
    "\n",
    "def build_n2v_model(teams_data):\n",
    "    G = nx.Graph()\n",
    "    for t in teams_data:\n",
    "        if 'team_name' in t: G.add_node(t['team_name'])\n",
    "    for i in range(len(teams_data)):\n",
    "        for j in range(i + 1, len(teams_data)):\n",
    "            tags1 = set(teams_data[i].get('style_tags', []))\n",
    "            tags2 = set(teams_data[j].get('style_tags', []))\n",
    "            common = len(tags1.intersection(tags2))\n",
    "            if common > 0:\n",
    "                G.add_edge(teams_data[i]['team_name'], teams_data[j]['team_name'], weight=common)\n",
    "    n2v = Node2Vec(G, dimensions=64, walk_length=10, num_walks=40, workers=1, quiet=True)\n",
    "    return n2v.fit(window=5, min_count=1)\n",
    "\n",
    "print(\"ğŸš€ íŒ€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘...\")\n",
    "teams_master = load_teams(DATA_DIR)\n",
    "n2v_model = build_n2v_model(teams_master)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹¤ì‹œê°„ ì ìˆ˜ ê³„ì‚° (SBERT ìœ ì§€ + ë¦¬ë”ë‹˜ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§)\n",
    "# ---------------------------------------------------------\n",
    "def get_scores_strict(user_query, anchor_name, candidate):\n",
    "    # (1) sbert_score: ê¸°ì¡´ SBERT ëª¨ë¸ ì‚¬ìš©\n",
    "    cand_tags = \" \".join(candidate.get('style_tags', []))\n",
    "    embs = model_sbert.encode([user_query, cand_tags])\n",
    "    s_sem = cosine_similarity([embs[0]], [embs[1]])[0][0]\n",
    "\n",
    "    # (2) n2v_score: ê´€ê³„ ìœ ì‚¬ë„\n",
    "    s_rel = 0.5\n",
    "    if anchor_name and anchor_name in n2v_model.wv and candidate['team_name'] in n2v_model.wv:\n",
    "        s_rel = n2v_model.wv.similarity(anchor_name, candidate['team_name'])\n",
    "\n",
    "    # (3) vector_score: ë¦¬ë”ë‹˜ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§ ì ìš©\n",
    "    ts = candidate.get('scores', {})\n",
    "    metrics = ['strength', 'money', 'star_power', 'attack_style', 'underdog_feel', 'fan_passion', 'tradition']\n",
    "    t_vec = np.array([ts.get(m, 10) for m in metrics])\n",
    "    \n",
    "    target_vec = np.array([10]*7)\n",
    "    s_multiplier = 1.0\n",
    "\n",
    "    # --- ë¦¬ë”ë‹˜ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§ (ìˆ˜ì • ì ˆëŒ€ ì—†ìŒ) ---\n",
    "    if any(k in user_query for k in [\"ì–¸ë”ë…\", \"ê¸°ì \", \"ì €ë¹„ìš©\", \"ë¨¸ë‹ˆë³¼\", \"íš¨ìœ¨\", \"ê°€ì„±ë¹„\"]):\n",
    "        target_vec[4] = 50\n",
    "        if ts.get('money', 10) >= 16: s_multiplier = 0.3\n",
    "        elif ts.get('money', 10) <= 8: s_multiplier = 1.5\n",
    "    elif any(k in user_query for k in [\"ê°•í•œ\", \"ì••ë„ì \", \"ìµœê°•\", \"ìš°ìŠ¹\", \"ë¶€ì\"]):\n",
    "        target_vec[0], target_vec[1] = 40, 40\n",
    "        if ts.get('strength', 10) < 12: s_multiplier = 0.4\n",
    "    elif any(k in user_query for k in [\"ë¯¸ë‚¨\", \"ì˜ìƒê¸´\", \"ë¹„ì£¼ì–¼\", \"ì–¼êµ´\", \"ì…ë•\", \"ìŠ¤íƒ€\"]):\n",
    "        target_vec[2] = 50\n",
    "        if ts.get('star_power', 10) < 12: s_multiplier = 0.4\n",
    "    elif any(k in user_query for k in [\"ì „í†µ\", \"ëª…ë¬¸\", \"ì—­ì‚¬\", \"ì—°ê³ ì§€\", \"ìë¶€ì‹¬\"]):\n",
    "        target_vec[6], target_vec[5] = 40, 40\n",
    "        if ts.get('tradition', 10) < 10: s_multiplier = 0.5\n",
    "    elif any(k in user_query for k in [\"ê³µê²©\", \"í™”ëˆ\", \"ë“ì \", \"í™ˆëŸ°\", \"ì¶”ì›”\", \"ì‹œì›ì‹œì›\"]):\n",
    "        target_vec[3] = 50\n",
    "        if ts.get('attack_style', 10) < 12: s_multiplier = 0.5\n",
    "    elif any(k in user_query for k in [\"ìˆ˜ë¹„\", \"ë‹¨ë‹¨í•œ\", \"ì‹¤ë¦¬\", \"ì—­ìŠµ\", \"ì§ˆì‹\"]):\n",
    "        target_vec[4], target_vec[0] = 30, 30\n",
    "        if ts.get('attack_style', 10) > 15: s_multiplier = 0.5\n",
    "    # ----------------------------------------\n",
    "\n",
    "    s_vec = cosine_similarity(target_vec.reshape(1, -1), t_vec.reshape(1, -1))[0][0]\n",
    "    s_vec = s_vec * s_multiplier\n",
    "    \n",
    "    return s_sem, s_rel, s_vec\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì¶”ì²œ ì„œë¹„ìŠ¤ (PCA ì „ìš© ëª¨ë¸ ì‚¬ìš©)\n",
    "# ---------------------------------------------------------\n",
    "def recommend_service(query, user_type, support_team, target_league):\n",
    "    json_league_name = LEAGUE_MAP.get(target_league, target_league)\n",
    "    candidates = [t for t in teams_master if t.get('league', '').lower() == json_league_name.lower()]\n",
    "    \n",
    "    if not candidates: return f\"'{target_league}' ë°ì´í„° ì—†ìŒ\"\n",
    "\n",
    "    # [ìˆ˜ì •] PCAìš© ë²¡í„°í™”ë§Œ ko-sroberta ëª¨ë¸ ì‚¬ìš©\n",
    "    query_pca_vec = model_pca_encoder.encode([query])\n",
    "    query_pca = pca.transform(query_pca_vec)[0]\n",
    "    pca_cols = [\"ì˜ë„_íŒ¬ë¤ì •ì²´ì„±\", \"ì˜ë„_ìŠ¤íƒ€ì„±ê³¼ê°•í•¨\", \"ì˜ë„_ëª…ë¬¸ê³¼ê¸°ì \", \"ì˜ë„_ë¹„ì£¼ì–¼ê³¼ë§¤ë ¥\", \"ì˜ë„_ìë³¸ê³¼ì§€ë°°ë ¥\"]\n",
    "\n",
    "    rows = []\n",
    "    for cand in candidates:\n",
    "        s_sem, s_rel, s_vec = get_scores_strict(query, support_team, cand)\n",
    "        \n",
    "        # ìˆ˜ë™ ì ìˆ˜ í•©ì‚°\n",
    "        manual_match_score = (s_sem * ALPHA) + (s_rel * BETA) + (s_vec * GAMMA)\n",
    "\n",
    "        row = {\n",
    "            'matching_team': cand['team_name'],\n",
    "            'user_type': int(user_type),\n",
    "            'recommend_league': json_league_name,\n",
    "            'sbert_score': s_sem, 'n2v_score': s_rel, 'vector_score': s_vec,\n",
    "            'manual_match_score': manual_match_score\n",
    "        }\n",
    "        for i, col in enumerate(pca_cols): row[col] = query_pca[i]\n",
    "        rows.append(row)\n",
    "\n",
    "    df_inf = pd.DataFrame(rows)\n",
    "    df_inf['recommend_league_enc'] = le_league.transform(df_inf['recommend_league'].astype(str))\n",
    "    \n",
    "    # ìŠ¤ì¼€ì¼ë§ ë° AI ëª¨ë¸ ì˜ˆì¸¡\n",
    "    score_cols = ['sbert_score', 'n2v_score', 'vector_score']\n",
    "    scaled = scaler.transform(df_inf[score_cols])\n",
    "    df_inf['sbert_score_mm'], df_inf['n2v_score_mm'], df_inf['vector_score_mm'] = scaled[:,0], scaled[:,1], scaled[:,2]\n",
    "\n",
    "    X_input = df_inf[input_features]\n",
    "    cat_cols = [c for c in [\"user_type\", \"recommend_league_enc\"] if c in input_features]\n",
    "    for c in cat_cols: X_input[c] = X_input[c].astype('category')\n",
    "\n",
    "    df_inf['predict_score'] = final_model.predict(X_input)\n",
    "\n",
    "    # ìµœì¢… 8:2 í•˜ì´ë¸Œë¦¬ë“œ ê²°í•©\n",
    "    df_inf['final_hybrid_score'] = (df_inf['manual_match_score'] * 0.8) + (df_inf['predict_score'] * 0.2)\n",
    "\n",
    "    return df_inf.sort_values(by='final_hybrid_score', ascending=False).head(5)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. ì‹¤í–‰ë¶€\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "user_q = input(\"ğŸ’¬ ì„ í˜¸ ìŠ¤íƒ€ì¼ ì…ë ¥: \")\n",
    "ut = input(\"ğŸ’¬ íŒ¬ ì—¬ë¶€ (1/0): \")\n",
    "my_team = input(\"ğŸ’¬ í˜„ì¬ ì‘ì›íŒ€: \") if ut == '1' else None\n",
    "target = input(\"ğŸ’¬ ì¶”ì²œë°›ì„ ë¦¬ê·¸ (EPL/Kë¦¬ê·¸/KBO/F1): \")\n",
    "\n",
    "res = recommend_service(user_q, ut, my_team, target)\n",
    "\n",
    "if isinstance(res, str):\n",
    "    print(f\"\\nâš ï¸ {res}\")\n",
    "else:\n",
    "    print(f\"\\nâœ¨ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ê²°ê³¼:\")\n",
    "    for i, row in enumerate(res.itertuples(), 1):\n",
    "        print(f\"{i}ìœ„: {row.matching_team} [ì¢…í•©: {row.final_hybrid_score:.4f} (ì‹œë‚˜ë¦¬ì˜¤: {row.manual_match_score:.4f} / AI: {row.predict_score:.4f})]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b23e721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a6ed70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” s_sem ê³„ì‚°ìš© SBERT ëª¨ë¸(KR-SBERT) ë¡œë”© ì¤‘...\n",
      "ğŸ” PCA ì¸ì½”ë”ìš© E5 ëª¨ë¸(multilingual-e5-base) ë¡œë”© ì¤‘...\n",
      "âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸš€ íŒ€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê´€ê³„ë§ì„ êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤...\n",
      "\n",
      "==================================================\n",
      "       ğŸ† ìŠ¤í¬ì¸  íŒ€ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì—”ì§„ (E5 ì ìš©)\n",
      "==================================================\n",
      "\n",
      "âœ¨ 'K LEAGUE' ë¦¬ê·¸ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼:\n",
      "â­ 1ìœ„: ì „ë¶ í˜„ëŒ€ ëª¨í„°ìŠ¤\n",
      "    - ì¢…í•© ì ìˆ˜: 0.2786 (ì‹œë‚˜ë¦¬ì˜¤: 0.3362 / AI ì˜ˆì¸¡: -0.2401)\n",
      "â­ 2ìœ„: ìˆ˜ì› ì‚¼ì„± ë¸”ë£¨ìœ™ì¦ˆ\n",
      "    - ì¢…í•© ì ìˆ˜: 0.2578 (ì‹œë‚˜ë¦¬ì˜¤: 0.4821 / AI ì˜ˆì¸¡: -1.7609)\n",
      "â­ 3ìœ„: ëŒ€êµ¬FC\n",
      "    - ì¢…í•© ì ìˆ˜: 0.2573 (ì‹œë‚˜ë¦¬ì˜¤: 0.5780 / AI ì˜ˆì¸¡: -2.6290)\n",
      "   4ìœ„: ê°•ì›FC\n",
      "    - ì¢…í•© ì ìˆ˜: 0.2368 (ì‹œë‚˜ë¦¬ì˜¤: 0.5533 / AI ì˜ˆì¸¡: -2.6120)\n",
      "   5ìœ„: ì¸ì²œ ìœ ë‚˜ì´í‹°ë“œ\n",
      "    - ì¢…í•© ì ìˆ˜: 0.2276 (ì‹œë‚˜ë¦¬ì˜¤: 0.4815 / AI ì˜ˆì¸¡: -2.0577)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import joblib\n",
    "import warnings\n",
    "from node2vec import Node2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ëª¨ë¸ ë° í™˜ê²½ ì„¤ì • (ì´ì›í™” ë¡œë”©)\n",
    "# ---------------------------------------------------------\n",
    "DATA_DIR = r'./JSON ëª¨ìŒ'\n",
    "\n",
    "# [ëª¨ë¸ 1] s_sem(ì˜ë¯¸ ìœ ì‚¬ë„) ì „ìš©: ê¸°ì¡´ SBERT ìœ ì§€\n",
    "print(\"ğŸ” s_sem ê³„ì‚°ìš© SBERT ëª¨ë¸(KR-SBERT) ë¡œë”© ì¤‘...\")\n",
    "model_sbert = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# [ëª¨ë¸ 2] PCA(ì˜ë„ ë¶„ì„) ì „ìš©: ìµœì‹  E5 ëª¨ë¸ ì ìš©\n",
    "print(\"ğŸ” PCA ì¸ì½”ë”ìš© E5 ëª¨ë¸(multilingual-e5-base) ë¡œë”© ì¤‘...\")\n",
    "model_pca_encoder = SentenceTransformer('intfloat/multilingual-e5-base')\n",
    "\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.4, 0.2\n",
    "\n",
    "LEAGUE_MAP = {\n",
    "    \"Kë¦¬ê·¸\": \"K league\", \"EPL\": \"EPL\", \"KBO\": \"KBO\", \"F1\": \"F1\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('sports_chatbot_model2.joblib')\n",
    "    final_model = artifacts['final_model']\n",
    "    pca = artifacts['pca']\n",
    "    scaler = artifacts['scaler']\n",
    "    le_league = artifacts['le_league']\n",
    "    input_features = artifacts['input_features']\n",
    "    print(\"âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ë°ì´í„° ë¡œë”© ë° N2V êµ¬ì¶• (ê¸°ì¡´ ìœ ì§€)\n",
    "# ---------------------------------------------------------\n",
    "def load_teams(path):\n",
    "    teams = []\n",
    "    if not os.path.exists(path): return teams\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n",
    "                    teams.append(json.load(f))\n",
    "    return teams\n",
    "\n",
    "def build_n2v_model(teams_data):\n",
    "    G = nx.Graph()\n",
    "    for t in teams_data:\n",
    "        if 'team_name' in t: G.add_node(t['team_name'])\n",
    "    for i in range(len(teams_data)):\n",
    "        for j in range(i + 1, len(teams_data)):\n",
    "            tags1 = set(teams_data[i].get('style_tags', []))\n",
    "            tags2 = set(teams_data[j].get('style_tags', []))\n",
    "            common = len(tags1.intersection(tags2))\n",
    "            if common > 0:\n",
    "                G.add_edge(teams_data[i]['team_name'], teams_data[j]['team_name'], weight=common)\n",
    "    n2v = Node2Vec(G, dimensions=64, walk_length=10, num_walks=40, workers=1, quiet=True)\n",
    "    return n2v.fit(window=10, min_count=1)\n",
    "\n",
    "print(\"ğŸš€ íŒ€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê´€ê³„ë§ì„ êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "teams_master = load_teams(DATA_DIR)\n",
    "n2v_model = build_n2v_model(teams_master)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ì‹¤ì‹œê°„ ì ìˆ˜ ê³„ì‚° (SBERT ê¸°ë°˜ + ë¦¬ë”ë‹˜ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§)\n",
    "# ---------------------------------------------------------\n",
    "def get_scores_strict(user_query, anchor_name, candidate):\n",
    "    # (1) sbert_score: ê¸°ì¡´ SBERT ëª¨ë¸ë¡œ ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    cand_tags = \" \".join(candidate.get('style_tags', []))\n",
    "    embs = model_sbert.encode([user_query, cand_tags])\n",
    "    s_sem = cosine_similarity([embs[0]], [embs[1]])[0][0]\n",
    "\n",
    "    # (2) n2v_score: ê´€ê³„ ìœ ì‚¬ë„\n",
    "    s_rel = 0.5\n",
    "    if anchor_name and anchor_name in n2v_model.wv and candidate['team_name'] in n2v_model.wv:\n",
    "        s_rel = n2v_model.wv.similarity(anchor_name, candidate['team_name'])\n",
    "\n",
    "    # (3) vector_score: [ë¦¬ë”ë‹˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§ ë°˜ì˜]\n",
    "    ts = candidate.get('scores', {})\n",
    "    metrics = ['strength', 'money', 'star_power', 'attack_style', 'underdog_feel', 'fan_passion', 'tradition']\n",
    "    t_vec = np.array([ts.get(m, 10) for m in metrics])\n",
    "    \n",
    "    target_vec = np.array([10]*7)\n",
    "    s_multiplier = 1.0\n",
    "\n",
    "    # ë¦¬ë”ë‹˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ ì¡°ê±´ë¬¸ (ìˆ˜ì • ì—†ìŒ)\n",
    "    if any(k in user_query for k in [\"ì–¸ë”ë…\", \"ê¸°ì \", \"ì €ë¹„ìš©\", \"ë¨¸ë‹ˆë³¼\", \"íš¨ìœ¨\", \"ê°€ì„±ë¹„\"]):\n",
    "        target_vec[4] = 50\n",
    "        if ts.get('money', 10) >= 16: s_multiplier = 0.3\n",
    "        elif ts.get('money', 10) <= 8: s_multiplier = 1.5\n",
    "    elif any(k in user_query for k in [\"ê°•í•œ\", \"ì••ë„ì \", \"ìµœê°•\", \"ìš°ìŠ¹\", \"ë¶€ì\"]):\n",
    "        target_vec[0], target_vec[1] = 40, 40\n",
    "        if ts.get('strength', 10) < 12: s_multiplier = 0.4\n",
    "    elif any(k in user_query for k in [\"ë¯¸ë‚¨\", \"ì˜ìƒê¸´\", \"ë¹„ì£¼ì–¼\", \"ì–¼êµ´\", \"ì…ë•\"]):\n",
    "        target_vec[2] = 50\n",
    "        if ts.get('star_power', 10) < 12: s_multiplier = 0.4\n",
    "    elif any(k in user_query for k in [\"ì „í†µ\", \"ëª…ë¬¸\", \"ì—­ì‚¬\", \"ì—°ê³ ì§€\", \"ìë¶€ì‹¬\"]):\n",
    "        target_vec[6], target_vec[5] = 40, 40\n",
    "        if ts.get('tradition', 10) < 10: s_multiplier = 0.5\n",
    "    elif any(k in user_query for k in [\"ê³µê²©\", \"í™”ëˆ\", \"ë“ì \", \"í™ˆëŸ°\", \"ì¶”ì›”\", \"ì‹œì›ì‹œì›\"]):\n",
    "        target_vec[3] = 50\n",
    "        if ts.get('attack_style', 10) < 12: s_multiplier = 0.5\n",
    "    elif any(k in user_query for k in [\"ìˆ˜ë¹„\", \"ë‹¨ë‹¨í•œ\", \"ì‹¤ë¦¬\", \"ì—­ìŠµ\", \"ì§ˆì‹\"]):\n",
    "        target_vec[4], target_vec[0] = 30, 30\n",
    "        if ts.get('attack_style', 10) > 15: s_multiplier = 0.5\n",
    "\n",
    "    s_vec = cosine_similarity(target_vec.reshape(1, -1), t_vec.reshape(1, -1))[0][0]\n",
    "    s_vec = s_vec * s_multiplier\n",
    "    \n",
    "    return s_sem, s_rel, s_vec\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì¶”ì²œ ì„œë¹„ìŠ¤ (E5 ì ‘ë‘ì‚¬ + í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§)\n",
    "# ---------------------------------------------------------\n",
    "def recommend_service(query, user_type, support_team, target_league):\n",
    "    json_league_name = LEAGUE_MAP.get(target_league, target_league)\n",
    "    candidates = [t for t in teams_master if t.get('league', '').lower() == json_league_name.lower()]\n",
    "    \n",
    "    if not candidates: return f\"'{target_league}' ë¦¬ê·¸ì˜ íŒ€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # [ìˆ˜ì •] E5 ëª¨ë¸ íŠ¹ì„±ìƒ ì§ˆë¬¸ ì•ì— 'query: ' ì ‘ë‘ì‚¬ë¥¼ ì¶”ê°€í•˜ì—¬ ë²¡í„°í™” ìˆ˜í–‰\n",
    "    e5_query = f\"query: {query}\"\n",
    "    query_pca_vec = model_pca_encoder.encode([e5_query])\n",
    "    query_pca = pca.transform(query_pca_vec)[0]\n",
    "    \n",
    "    pca_cols = [\"ì˜ë„_íŒ¬ë¤ì •ì²´ì„±\", \"ì˜ë„_ìŠ¤íƒ€ì„±ê³¼ê°•í•¨\", \"ì˜ë„_ëª…ë¬¸ê³¼ê¸°ì \", \"ì˜ë„_ë¹„ì£¼ì–¼ê³¼ë§¤ë ¥\", \"ì˜ë„_ìë³¸ê³¼ì§€ë°°ë ¥\"]\n",
    "\n",
    "    rows = []\n",
    "    for cand in candidates:\n",
    "        s_sem, s_rel, s_vec = get_scores_strict(query, support_team, cand)\n",
    "        \n",
    "        # ìˆ˜ë™ ì ìˆ˜ ê³„ì‚° (80% ë°˜ì˜ë  í•µì‹¬ ì ìˆ˜)\n",
    "        manual_match_score = (s_sem * ALPHA) + (s_rel * BETA) + (s_vec * GAMMA)\n",
    "\n",
    "        row = {\n",
    "            'matching_team': cand['team_name'],\n",
    "            'user_type': int(user_type),\n",
    "            'recommend_league': json_league_name,\n",
    "            'sbert_score': s_sem, 'n2v_score': s_rel, 'vector_score': s_vec,\n",
    "            'manual_match_score': manual_match_score\n",
    "        }\n",
    "        for i, col in enumerate(pca_cols): row[col] = query_pca[i]\n",
    "        rows.append(row)\n",
    "\n",
    "    df_inf = pd.DataFrame(rows)\n",
    "    df_inf['recommend_league_enc'] = le_league.transform(df_inf['recommend_league'].astype(str))\n",
    "    \n",
    "    # MinMaxScaler ì ìš© ë° AI ëª¨ë¸ ì˜ˆì¸¡\n",
    "    score_cols = ['sbert_score', 'n2v_score', 'vector_score']\n",
    "    scaled = scaler.transform(df_inf[score_cols])\n",
    "    df_inf['sbert_score_mm'], df_inf['n2v_score_mm'], df_inf['vector_score_mm'] = scaled[:,0], scaled[:,1], scaled[:,2]\n",
    "\n",
    "    X_input = df_inf[input_features]\n",
    "    cat_cols = [c for c in [\"user_type\", \"recommend_league_enc\"] if c in input_features]\n",
    "    for c in cat_cols: X_input[c] = X_input[c].astype('category')\n",
    "\n",
    "    df_inf['predict_score'] = final_model.predict(X_input)\n",
    "\n",
    "    # ìµœì¢… 8:2 í•˜ì´ë¸Œë¦¬ë“œ ê²°í•© (ìˆ˜ë™ ë¡œì§ 0.8, í•™ìŠµ ëª¨ë¸ 0.2)\n",
    "    df_inf['final_hybrid_score'] = (df_inf['manual_match_score'] * 0.9) + (df_inf['predict_score'] * 0.1)\n",
    "\n",
    "    return df_inf.sort_values(by='final_hybrid_score', ascending=False).head(5)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. ì‹¤í–‰ë¶€\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"       ğŸ† ìŠ¤í¬ì¸  íŒ€ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì—”ì§„ (E5 ì ìš©)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "user_q = input(\"ğŸ’¬ ì›í•˜ì‹œëŠ” íŒ€ì˜ ë¶„ìœ„ê¸°ë‚˜ íŠ¹ì§•ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: \")\n",
    "ut = input(\"ğŸ’¬ ìŠ¤í¬ì¸  íŒ¬ ì—¬ë¶€ (1:íŒ¬, 0:ì…ë¬¸ì): \")\n",
    "my_team = input(\"ğŸ’¬ í˜„ì¬ ì‘ì› ì¤‘ì¸ íŒ€ (ì—†ìœ¼ë©´ ì—”í„°): \") if ut == '1' else None\n",
    "target = input(\"ğŸ’¬ ì¶”ì²œ ë¦¬ê·¸ ì„ íƒ (EPL/Kë¦¬ê·¸/KBO/F1): \")\n",
    "\n",
    "res = recommend_service(user_q, ut, my_team, target)\n",
    "\n",
    "if isinstance(res, str):\n",
    "    print(f\"\\nâš ï¸ {res}\")\n",
    "else:\n",
    "    print(f\"\\nâœ¨ '{target}' ë¦¬ê·¸ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼:\")\n",
    "    for i, row in enumerate(res.itertuples(), 1):\n",
    "        star = \"â­\" if i <= 3 else \"  \"\n",
    "        print(f\"{star} {i}ìœ„: {row.matching_team}\")\n",
    "        print(f\"    - ì¢…í•© ì ìˆ˜: {row.final_hybrid_score:.4f} (ì‹œë‚˜ë¦¬ì˜¤: {row.manual_match_score:.4f} / AI ì˜ˆì¸¡: {row.predict_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889860fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60782b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
