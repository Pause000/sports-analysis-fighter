import re
import time
from pathlib import Path
from googletrans import Translator


# =============================
# 1) í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
# =============================
def clean_text(text: str) -> str:
    text = text.replace("\ufeff", "")              # BOM ì œê±°
    text = text.replace("\u200b", "")              # zero-width ë¬¸ì ì œê±°
    text = re.sub(r"http[s]?://\S+", " ", text)    # URL ì œê±°
    text = re.sub(r"[\r\t]", " ", text)            # \r, \t ì œê±°
    text = re.sub(r"\n{3,}", "\n\n", text)         # ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = text.replace("!", " ").replace("?", " ")
    text = re.sub(r"[^0-9A-Za-zê°€-í£\s\.\n]", " ", text)
    text = re.sub(r"[ ]{2,}", " ", text)
    text = re.sub(r"[ ]+\n", "\n", text)
    text = re.sub(r"\n[ ]+", "\n", text)
    return text.strip()


# =============================
# 2) ë¬¸ì¥ í›„ì²˜ë¦¬
# =============================
def postprocess_sentences(text: str, min_len=1, merge_len=25) -> str:
    text = re.sub(r"\s*\n+\s*", " ", text)
    text = re.sub(r"\s{2,}", " ", text).strip()

    parts = re.split(r"\s*\.\s*", text)

    result = []
    seen = set()

    for part in parts:
        sent = part.strip()
        if not sent or len(sent) < min_len:
            continue

        if len(sent) <= merge_len and result:
            result[-1] = f"{result[-1]} {sent}".strip()
            continue

        key = re.sub(r"\s+", " ", sent)
        if key in seen:
            continue

        seen.add(key)
        result.append(sent)

    return ".\n".join(result) + ("." if result else "")


# =============================
# 3) ë²ˆì—­ ê´€ë ¨ í•¨ìˆ˜
# =============================
def contains_korean(text: str) -> bool:
    return any("ê°€" <= ch <= "í£" for ch in text)


def split_text(text: str, max_length=4000):
    chunks = []
    while len(text) > max_length:
        cut = text.rfind(" ", 0, max_length)
        if cut == -1:
            cut = max_length
        chunks.append(text[:cut])
        text = text[cut:]
    chunks.append(text)
    return chunks


def safe_translate(translator, text, src="ko", dest="en"):
    for attempt in range(3):
        try:
            return translator.translate(text, src=src, dest=dest).text
        except Exception as e:
            print(f"[ERROR] ë²ˆì—­ ì‹¤íŒ¨ ({attempt+1}/3): {e}")
            time.sleep(2)
    return ""


# =============================
# 4) í•µì‹¬ ë¡œì§
# =============================
def merge_preprocess_translate(
    input_dir: str,
    output_file: str,
):
    input_path = Path(input_dir)
    txt_files = sorted(input_path.glob("*.txt"))

    if not txt_files:
        print("âŒ í´ë”ì— txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ í…ìŠ¤íŠ¸ íŒŒì¼ {len(txt_files)}ê°œ ë³‘í•© ì‹œì‘")

    # 1ï¸âƒ£ ëª¨ë“  íŒŒì¼ ë³‘í•©
    merged_texts = []
    for file in txt_files:
        print(f"   - ë³‘í•© ì¤‘: {file.name}")
        merged_texts.append(
            file.read_text(encoding="utf-8", errors="ignore")
        )

    merged_text = "\n".join(merged_texts)
    print(f"â–¶ ë³‘í•© í›„ ê¸¸ì´: {len(merged_text)}ì")

    # 2ï¸âƒ£ ì „ì²˜ë¦¬
    cleaned = clean_text(merged_text)
    cleaned = postprocess_sentences(cleaned)
    print(f"â–¶ ì „ì²˜ë¦¬ í›„ ê¸¸ì´: {len(cleaned)}ì")

    # 3ï¸âƒ£ ë²ˆì—­
    if not contains_korean(cleaned):
        print("âš ï¸ í•œê¸€ ì—†ìŒ â†’ ë²ˆì—­ ìƒëµ")
        final_text = cleaned
    else:
        translator = Translator()
        chunks = split_text(cleaned)
        translated_chunks = []

        for i, chunk in enumerate(chunks):
            print(f"â³ ë²ˆì—­ ì¤‘... ({i+1}/{len(chunks)})")
            translated_chunks.append(safe_translate(translator, chunk))
            time.sleep(1)

        final_text = "\n".join(translated_chunks)

    # 4ï¸âƒ£ ìµœì¢… ê²°ê³¼ ì €ì¥ (1ê°œ íŒŒì¼)
    Path(output_file).write_text(final_text, encoding="utf-8")
    print("âœ… ì™„ë£Œ")
    print(f"â–¶ ì €ì¥ ìœ„ì¹˜: {output_file}")
    print(f"â–¶ ìµœì¢… ê¸¸ì´: {len(final_text)}ì")


# =============================
# ì‹¤í–‰ë¶€
# =============================
if __name__ == "__main__":
    merge_preprocess_translate(
        input_dir=r"", # ë²ˆì—­í•  í´ë”
        output_file=r"", # ì €ì¥í•  ìœ„ì¹˜
    )