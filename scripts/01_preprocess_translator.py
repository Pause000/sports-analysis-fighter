import re
import time
import os
import random
from pathlib import Path
# Python 3.13 í˜¸í™˜ì„±ì„ ìœ„í•´ deep-translator ì‚¬ìš© (pip install deep-translator í•„ìš”)
from deep_translator import GoogleTranslator

# =============================
# 1) ê¸°ì¡´ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ìœ ì§€)
# =============================
def clean_text(text: str) -> str:
    text = text.replace("\ufeff", "")
    text = text.replace("\u200b", "")
    text = re.sub(r"http[s]?://\S+", " ", text)
    text = re.sub(r"[\r\t]", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = text.replace("!", " ").replace("?", " ")
    text = re.sub(r"[^0-9A-Za-zê°€-í£\s\.\n]", " ", text)
    text = re.sub(r"[ ]{2,}", " ", text)
    return text.strip()

# =============================
# 2) ê¸°ì¡´ í›„ì²˜ë¦¬ ë¡œì§ (ìœ ì§€: ë¬¸ì¥ë³„ .\n êµ¬ë¶„)
# =============================
def postprocess_sentences(text: str, min_len=1, merge_len=25) -> list:
    # ğŸ’¡ ë‚˜ì¤‘ì— ë²ˆì—­í•˜ê¸° í¸í•˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•˜ê²Œ ì‚´ì§ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
    text = re.sub(r"\s*\n+\s*", " ", text)
    text = re.sub(r"\s{2,}", " ", text).strip()
    parts = re.split(r"\s*\.\s*", text)
    
    result = []
    seen = set()
    for part in parts:
        sent = part.strip()
        if not sent or len(sent) < min_len: continue
        if len(sent) <= merge_len and result:
            result[-1] = f"{result[-1]} {sent}".strip()
            continue
        key = re.sub(r"\s+", " ", sent)
        if key in seen: continue
        seen.add(key)
        result.append(sent)
    return result # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

# =============================
# 3) ë²ˆì—­ í•¨ìˆ˜ (deep-translatorë¡œ ì•ˆì •í™”)
# =============================
def safe_translate(text, src="ko", dest="en"):
    if not any("ê°€" <= ch <= "í£" for ch in text): return text
    for attempt in range(3):
        try:
            # ë¬¸ì¥ ë‹¨ìœ„ ë²ˆì—­ìœ¼ë¡œ êµ¬ì¡° ë¶•ê´´ ë°©ì§€
            return GoogleTranslator(source=src, target=dest).translate(text)
        except Exception as e:
            print(f"      âš ï¸ ë²ˆì—­ ì¬ì‹œë„ ({attempt+1}/3): {e}")
            time.sleep(random.uniform(1, 2))
    return text

# =============================
# 4) í•µì‹¬ ë¡œì§
# =============================
def merge_preprocess_translate(input_dir: str, output_path: str):
    input_path_obj = Path(input_dir).resolve()
    output_path_obj = Path(output_path).resolve()
    txt_files = sorted(input_path_obj.glob("*.txt"))

    if not txt_files:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path_obj}")
        return

    os.makedirs(output_path_obj, exist_ok=True)
    print(f"ğŸš€ {len(txt_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ (ì „ì²˜ë¦¬ ë¡œì§ ë³´ì¡´ ëª¨ë“œ)")

    for idx, file in enumerate(txt_files):
        print(f"â–¶ [{idx+1}/{len(txt_files)}] {file.name} ì²˜ë¦¬ ì¤‘...")
        content = file.read_text(encoding="utf-8", errors="ignore")
        
        # 1. ì›ë³¸ ì „ì²˜ë¦¬ ì ìš©
        cleaned_text = clean_text(content)
        sentence_list = postprocess_sentences(cleaned_text) # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ íšë“
        
        # 2. ë¬¸ì¥ë³„ ë²ˆì—­ (ì¤„ë°”ê¿ˆ ë³´ì¡´ì˜ í•µì‹¬)
        translated_sentences = []
        for i, sent in enumerate(sentence_list):
            # ì§„í–‰ë¥  í‘œì‹œ
            print(f"   ã„´ ë²ˆì—­ ì¤‘: {i+1}/{len(sentence_list)}", end="\r")
            trans_sent = safe_translate(sent)
            translated_sentences.append(trans_sent)
            
        # 3. ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ .\n ìœ¼ë¡œ í•©ì¹˜ê¸°
        final_text = ".\n".join(translated_sentences) + ("." if translated_sentences else "")

        # 4. ì €ì¥
        save_target = output_path_obj / f"{file.stem}_translated.txt"
        save_target.write_text(final_text, encoding="utf-8")
        print(f"\n   ğŸ’¾ ì €ì¥ ì™„ë£Œ: {save_target.name}")

if __name__ == "__main__":
    merge_preprocess_translate(
        input_dir=r"", 
        output_path=r""
    )