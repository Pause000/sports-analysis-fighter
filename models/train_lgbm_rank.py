import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import GroupShuffleSplit, ParameterGrid
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.decomposition import PCA
from sentence_transformers import SentenceTransformer
import warnings
import joblib
import matplotlib.pyplot as plt

# ë¶„ë¦¬í•œ í‰ê°€ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
from eval_metrics import calculate_mean_ndcg, plot_feature_importance

# 0) ì´ˆê¸° ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
warnings.filterwarnings("ignore")
plt.rcParams['font.family'] = 'Malgun Gothic'

df = pd.read_csv("final_data.csv")
df = df[df["llm_rank"] > 0].copy()
df["relevance"] = df["llm_rank"].map({1: 5, 2: 3, 3: 2}).fillna(0)

gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, test_idx = next(gss.split(df, groups=df["query"]))
train_df, test_df = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()

# 1) ì…ë ¥ í”¼ì²˜ ìƒì„± (ë¡œì§ ìˆ˜ì • ì—†ìŒ)
print("ğŸš€ [Step 1] ë§ˆìŠ¤í„° ëª…ë‹¨ ê¸°ë°˜ ì „ì²˜ë¦¬ ë° í”¼ì²˜ ìƒì„± ì‹œì‘...")

sbert = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
train_qs = train_df["query"].unique()
test_qs = test_df["query"].unique()
train_emb = sbert.encode(train_qs)
test_emb = sbert.encode(test_qs)

pca = PCA(n_components=5, random_state=42)
train_pca_vals = pca.fit_transform(train_emb)
test_pca_vals = pca.transform(test_emb)

pca_named_cols = ["ì˜ë„_íŒ¬ë¤ì •ì²´ì„±", "ì˜ë„_ìŠ¤íƒ€ì„±ê³¼ê°•í•¨", "ì˜ë„_ëª…ë¬¸ê³¼ê¸°ì ", "ì˜ë„_ë¹„ì£¼ì–¼ê³¼ë§¤ë ¥", "ì˜ë„_ìë³¸ê³¼ì§€ë°°ë ¥"]
train_q_map = {q: v for q, v in zip(train_qs, train_pca_vals)}
test_q_map = {q: v for q, v in zip(test_qs, test_pca_vals)}

train_df[pca_named_cols] = pd.DataFrame(train_df["query"].map(train_q_map).tolist(), index=train_df.index)
test_df[pca_named_cols] = pd.DataFrame(test_df["query"].map(test_q_map).tolist(), index=test_df.index)

# ë§ˆìŠ¤í„° íŒ€ ëª…ë‹¨ ê¸°ë°˜ LabelEncoder
master_team_list = [
    "ì•„ìŠ¤ë„", "ì•„ìŠ¤í†¤ ë¹Œë¼", "ë³¸ë¨¸ìŠ¤", "ë¸Œë ŒíŠ¸í¬ë“œ", "ë¸Œë¼ì´íŠ¼", "ì²¼ì‹œ", "í¬ë¦¬ìŠ¤íƒˆ íŒ°ë¦¬ìŠ¤", 
    "ì—ë²„í„´", "í’€ëŸ¼", "ì…ìŠ¤ìœ„ì¹˜ íƒ€ìš´", "ë ˆìŠ¤í„° ì‹œí‹°", "ë¦¬ë²„í’€", "ë§¨ì²´ìŠ¤í„° ì‹œí‹°", "ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œ", 
    "ë‰´ìºìŠ¬ ìœ ë‚˜ì´í‹°ë“œ", "ë…¸íŒ…ì—„ í¬ë ˆìŠ¤íŠ¸", "ì‚¬ìš°ìƒ˜í”„í„´", "í† íŠ¸ë„˜ í™‹ìŠ¤í¼", "ì›¨ìŠ¤íŠ¸í–„ ìœ ë‚˜ì´í‹°ë“œ", "ìš¸ë²„í–„íŠ¼ ì›ë”ëŸ¬ìŠ¤",
    "LG íŠ¸ìœˆìŠ¤", "KT ìœ„ì¦ˆ", "SSG ëœë”ìŠ¤", "NC ë‹¤ì´ë…¸ìŠ¤", "ë‘ì‚° ë² ì–´ìŠ¤", "ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ", 
    "ë¡¯ë° ìì´ì–¸ì¸ ", "ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ", "í•œí™” ì´ê¸€ìŠ¤", "í‚¤ì›€ íˆì–´ë¡œì¦ˆ",
    "ìš¸ì‚° HD FC", "í¬í•­ ìŠ¤í‹¸ëŸ¬ìŠ¤", "ê´‘ì£¼FC", "ì „ë¶ í˜„ëŒ€ ëª¨í„°ìŠ¤", "ëŒ€êµ¬FC", "ì¸ì²œ ìœ ë‚˜ì´í‹°ë“œ", 
    "FC ì„œìš¸", "ëŒ€ì „ í•˜ë‚˜ ì‹œí‹°ì¦Œ", "ì œì£¼ SK FC", "ê°•ì›FC", "FCì•ˆì–‘", "ìˆ˜ì› ì‚¼ì„± ë¸”ë£¨ìœ™ì¦ˆ",
    "ë ˆë“œë¶ˆ", "í˜ë¼ë¦¬", "ë©”ë¥´ì„¸ë°ìŠ¤", "ë§¥ë¼ë Œ", "ì• ìŠ¤í„´ ë§ˆí‹´", "ì•Œí•€", "ìœŒë¦¬ì—„ìŠ¤", "ë ˆì´ì‹± ë¶ˆìŠ¤", "ììš°ë²„", "í•˜ìŠ¤",
    "Unknown"
]

le_team = LabelEncoder()
le_team.fit(master_team_list)

def safe_encode(name, encoder):
    return encoder.transform([name if name in encoder.classes_ else "Unknown"])[0]

le_league = LabelEncoder()
train_df["recommend_league_enc"] = le_league.fit_transform(train_df["recommend_league"].astype(str))
test_df["recommend_league_enc"] = test_df["recommend_league"].astype(str).apply(lambda x: le_league.transform([x])[0] if x in le_league.classes_ else -1)

train_df["matching_team_enc"] = train_df["matching_team"].astype(str).apply(lambda x: safe_encode(x, le_team))
test_df["matching_team_enc"] = test_df["matching_team"].astype(str).apply(lambda x: safe_encode(x, le_team))

score_cols = ["sbert_score", "n2v_score", "vector_score"]
scaled_score_names = [f"{c}_mm" for c in score_cols]
scaler = MinMaxScaler()
train_df[scaled_score_names] = scaler.fit_transform(train_df[score_cols])
test_df[scaled_score_names] = scaler.transform(test_df[score_cols])

input_features = ["user_type", "recommend_league_enc"] + scaled_score_names + pca_named_cols

X_train, y_train = train_df[input_features], train_df["relevance"]
X_test, y_test = test_df[input_features], test_df["relevance"]

cat_features = ["user_type", "recommend_league_enc"]
for c in cat_features:
    X_train[c] = X_train[c].astype('category')
    X_test[c] = X_test[c].astype('category')

group_train = train_df.groupby("query").size().values

# 2) ê·¸ë¦¬ë“œ ì„œì¹˜ ë° ëª¨ë¸ ìµœì í™”
print("\nğŸš€ [Step 2] ëª¨ë¸ ìµœì í™” ì¤‘...")
param_grid = {
    'learning_rate': [0.03, 0.05],
    'max_depth': [4, 6],
    'n_estimators': [300, 500],
    'num_leaves': [20, 31],
    'random_state': [42]
}

best_score = -1
best_params = None

for params in ParameterGrid(param_grid):
    model = lgb.LGBMRanker(**params, importance_type='gain', verbosity=-1)
    model.fit(X_train, y_train, group=group_train)
    test_df["temp_preds"] = model.predict(X_test)
    # ë¶„ë¦¬ëœ calculate_mean_ndcg í•¨ìˆ˜ í˜¸ì¶œ
    cur_ndcg = calculate_mean_ndcg(test_df, "temp_preds")
    if cur_ndcg > best_score:
        best_score = cur_ndcg
        best_params = params

# 3) ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì‹œê°í™”
print(f"\nâœ¨ ìµœì  íŒŒë¼ë¯¸í„° ì¡°í•©: {best_params}")
final_model = lgb.LGBMRanker(**best_params)
final_model.fit(X_train, y_train, group=group_train)

test_df["final_preds"] = final_model.predict(X_test)
final_ndcg = calculate_mean_ndcg(test_df, "final_preds")

print("\n" + "="*45)
print(f"ğŸ† ìµœì¢… í…ŒìŠ¤íŠ¸ Mean NDCG: {final_ndcg:.4f}")
print("="*45)

# ë¶„ë¦¬ëœ plot_feature_importance í•¨ìˆ˜ í˜¸ì¶œ
plot_feature_importance(final_model, input_features, "ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ëª¨ë¸ í”¼ì²˜ ì¤‘ìš”ë„ (ì •ë‹µ ìœ ì¶œ ë°©ì§€ ë²„ì „)")

# 4) ì£¼ìš” êµ¬ì„± ìš”ì†Œ ì €ì¥ (ê¸°ì¡´ ì €ì¥ êµ¬ì¡° ìœ ì§€)
model_artifacts = {
    'le_team': le_team,
    'le_league': le_league,
    'scaler': scaler,
    'pca': pca,
    'final_model': final_model,
    'input_features': input_features
}
joblib.dump(model_artifacts, './saved_models/sports_chatbot_model.joblib')
print("âœ… ì„œë¹„ìŠ¤ìš© ëª¨ë¸ íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ!")