{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcea78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghks0\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 경고 메시지 숨김\n",
    "\n",
    "# =========================\n",
    "# 여기만 네 환경에 맞게 수정\n",
    "# =========================\n",
    "CSV_PATH = r\"C:\\work\\Project\\sports-analysis-fighter\\csv_파일\\찐최종.csv\"\n",
    "\n",
    "TEXT_COL = \"query\"\n",
    "GROUP_COL = \"query\"\n",
    "RANK_COL = \"llm_rank\"\n",
    "LEAGUE_COL = \"추천 리그\"\n",
    "\n",
    "# 팀 컬럼도 피처로 쓰고 싶으면 True\n",
    "USE_TEAM_COLS = True\n",
    "TEAM_COLS = [\"original_support_team\", \"matching_team\"]\n",
    "\n",
    "# 수치형 점수(스케일링 대상)\n",
    "SCORE_COLS = [\"sbert_score\", \"n2v_score\", \"vector_score\"]\n",
    "\n",
    "# SBERT + PCA + KMeans 설정\n",
    "SBERT_MODEL_NAME = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
    "PCA_DIM = 5\n",
    "N_CLUSTERS = 5\n",
    "\n",
    "# (옵션) TF-IDF + SVD 추가할지\n",
    "USE_TFIDF_SVD = True\n",
    "TFIDF_MAX_FEATURES = 5000\n",
    "SVD_DIM = 50\n",
    "\n",
    "# LGBMRanker 파라미터\n",
    "LGB_PARAMS = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    importance_type=\"gain\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae5ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: 데이터 로드 및 기본 전처리 진행 중...\n",
      "데이터 크기: (8857, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_type</th>\n",
       "      <th>original_support_team</th>\n",
       "      <th>query</th>\n",
       "      <th>matching_team</th>\n",
       "      <th>recommend_league</th>\n",
       "      <th>sbert_score</th>\n",
       "      <th>n2v_score</th>\n",
       "      <th>vector_score</th>\n",
       "      <th>match_score</th>\n",
       "      <th>llm_confidence</th>\n",
       "      <th>llm_rank</th>\n",
       "      <th>llm_reason</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>뉴캐슬 유나이티드</td>\n",
       "      <td>나는 뉴캐슬 유나이티드의 '70년 무관 탈출' 같은 스타일이 마음에 들어. 이런 느...</td>\n",
       "      <td>레이싱 불스</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.448592</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.924608</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>분석 실패 또는 신뢰도 낮음</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>뉴캐슬 유나이티드</td>\n",
       "      <td>나는 뉴캐슬 유나이티드의 '70년 무관 탈출' 같은 스타일이 마음에 들어. 이런 느...</td>\n",
       "      <td>페라리</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.354678</td>\n",
       "      <td>0.572448</td>\n",
       "      <td>0.867586</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>분석 실패 또는 신뢰도 낮음</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>뉴캐슬 유나이티드</td>\n",
       "      <td>나는 뉴캐슬 유나이티드의 '70년 무관 탈출' 같은 스타일이 마음에 들어. 이런 느...</td>\n",
       "      <td>레드불</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.389818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.869819</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>분석 실패 또는 신뢰도 낮음</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_type original_support_team  \\\n",
       "0          1             뉴캐슬 유나이티드   \n",
       "1          1             뉴캐슬 유나이티드   \n",
       "2          1             뉴캐슬 유나이티드   \n",
       "\n",
       "                                               query matching_team  \\\n",
       "0  나는 뉴캐슬 유나이티드의 '70년 무관 탈출' 같은 스타일이 마음에 들어. 이런 느...        레이싱 불스   \n",
       "1  나는 뉴캐슬 유나이티드의 '70년 무관 탈출' 같은 스타일이 마음에 들어. 이런 느...           페라리   \n",
       "2  나는 뉴캐슬 유나이티드의 '70년 무관 탈출' 같은 스타일이 마음에 들어. 이런 느...           레드불   \n",
       "\n",
       "  recommend_league  sbert_score  n2v_score  vector_score  match_score  \\\n",
       "0               F1     0.448592   0.500000      0.924608       0.5644   \n",
       "1               F1     0.354678   0.572448      0.867586       0.5444   \n",
       "2               F1     0.389818   0.500000      0.869819       0.5299   \n",
       "\n",
       "   llm_confidence  llm_rank       llm_reason  relevance  \n",
       "0             0.0         0  분석 실패 또는 신뢰도 낮음          3  \n",
       "1             0.0         0  분석 실패 또는 신뢰도 낮음          3  \n",
       "2             0.0         0  분석 실패 또는 신뢰도 낮음          3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step 1: 데이터 로드 및 기본 전처리 진행 중...\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 1) 핵심 컬럼 결측 제거\n",
    "df = df.dropna(subset=[TEXT_COL, GROUP_COL, RANK_COL]).copy()\n",
    "\n",
    "# 2) 텍스트는 문자열 보장\n",
    "df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "\n",
    "# 3) 수치형 컬럼 숫자 변환 (문자 섞이면 NaN)\n",
    "for c in SCORE_COLS:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df = df.dropna(subset=SCORE_COLS).copy()\n",
    "\n",
    "# 4) 타겟(relevance) 만들기\n",
    "#    llm_rank(1이 최고)를 \"값이 클수록 좋은 점수\"로 바꾸기\n",
    "#    ⚠️ 반드시 질문 그룹 내부에서 변환해야 랭킹 문제에 맞음\n",
    "df[\"relevance\"] = df.groupby(GROUP_COL)[RANK_COL].transform(lambda s: s.max() - s + 1)\n",
    "\n",
    "print(\"데이터 크기:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae63d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: 질문(Group) 기준 Train/Test 분리 진행 중...\n",
      "train: (7130, 13)  / test: (1727, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2: 질문(Group) 기준 Train/Test 분리 진행 중...\")\n",
    "\n",
    "X_dummy = df[[TEXT_COL]]\n",
    "y_dummy = df[\"relevance\"]\n",
    "groups = df[GROUP_COL]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X_dummy, y_dummy, groups))\n",
    "\n",
    "train_df = df.iloc[train_idx].copy()\n",
    "test_df = df.iloc[test_idx].copy()\n",
    "\n",
    "# group 배열이 행 순서에 의존하므로 질문 기준 정렬해두면 안전함\n",
    "train_df = train_df.sort_values(GROUP_COL).copy()\n",
    "test_df = test_df.sort_values(GROUP_COL).copy()\n",
    "\n",
    "print(\"train:\", train_df.shape, \" / test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f528ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: SBERT 임베딩 및 PCA 진행 중...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>3.396134</td>\n",
       "      <td>3.795578</td>\n",
       "      <td>-3.064728</td>\n",
       "      <td>0.571887</td>\n",
       "      <td>-0.245574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8738</th>\n",
       "      <td>3.396134</td>\n",
       "      <td>3.795578</td>\n",
       "      <td>-3.064728</td>\n",
       "      <td>0.571887</td>\n",
       "      <td>-0.245574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8739</th>\n",
       "      <td>3.396134</td>\n",
       "      <td>3.795578</td>\n",
       "      <td>-3.064728</td>\n",
       "      <td>0.571887</td>\n",
       "      <td>-0.245574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pca_0     pca_1     pca_2     pca_3     pca_4\n",
       "8727  3.396134  3.795578 -3.064728  0.571887 -0.245574\n",
       "8738  3.396134  3.795578 -3.064728  0.571887 -0.245574\n",
       "8739  3.396134  3.795578 -3.064728  0.571887 -0.245574"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step 3: SBERT 임베딩 및 PCA 진행 중...\")\n",
    "\n",
    "sbert = SentenceTransformer(SBERT_MODEL_NAME)\n",
    "\n",
    "# 질문 유니크를 train/test로 따로 뽑음\n",
    "train_questions = train_df[TEXT_COL].unique()\n",
    "test_questions = test_df[TEXT_COL].unique()\n",
    "\n",
    "# 1) 문장 -> 임베딩 벡터\n",
    "train_emb = sbert.encode(train_questions)\n",
    "test_emb = sbert.encode(test_questions)\n",
    "\n",
    "# 2) PCA는 train으로만 fit\n",
    "pca = PCA(n_components=PCA_DIM, random_state=42)\n",
    "train_pca = pca.fit_transform(train_emb)\n",
    "test_pca = pca.transform(test_emb)\n",
    "\n",
    "pca_cols = [f\"pca_{i}\" for i in range(PCA_DIM)]\n",
    "\n",
    "# 질문 -> PCA벡터 매핑\n",
    "train_q_to_pca = {q: v for q, v in zip(train_questions, train_pca)}\n",
    "test_q_to_pca = {q: v for q, v in zip(test_questions, test_pca)}\n",
    "\n",
    "# 데이터프레임에 PCA 피처 추가\n",
    "train_df[pca_cols] = pd.DataFrame(train_df[TEXT_COL].map(train_q_to_pca).tolist(), index=train_df.index)\n",
    "test_df[pca_cols] = pd.DataFrame(test_df[TEXT_COL].map(test_q_to_pca).tolist(), index=test_df.index)\n",
    "\n",
    "train_df[pca_cols].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5067bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: KMeans 질문 클러스터링 진행 중...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8738</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8739</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      q_cluster\n",
       "8727          2\n",
       "8738          2\n",
       "8739          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Step 4: KMeans 질문 클러스터링 진행 중...\")\n",
    "\n",
    "kmeans = KMeans(n_clusters = N_CLUSTERS, random_state=42, n_init=10)\n",
    "\n",
    "# KMeans는 train 질문 임베딩으로만 fit\n",
    "train_cluster = kmeans.fit_predict(train_emb)\n",
    "test_cluster = kmeans.predict(test_emb)\n",
    "\n",
    "# 질문 -> cluster 매핑\n",
    "train_q_to_cluster = {q: c for q, c in zip(train_questions, train_cluster)}\n",
    "test_q_to_cluster = {q: c for q, c in zip(test_questions, test_cluster)}\n",
    "\n",
    "# 데이터프레임에 q_cluster 추가\n",
    "train_df[\"q_cluster\"] = train_df[TEXT_COL].map(train_q_to_cluster).astype(int)\n",
    "test_df[\"q_cluster\"] = test_df[TEXT_COL].map(test_q_to_cluster).astype(int)\n",
    "\n",
    "train_df[[\"q_cluster\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e8fcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: TF-IDF + SVD 진행 중...\n",
      "SVD 피처 추가 완료: 50 개\n"
     ]
    }
   ],
   "source": [
    "if USE_TFIDF_SVD:\n",
    "    print(\"Step 5: TF-IDF + SVD 진행 중...\")\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1, 2))\n",
    "    train_tfidf = tfidf.fit_transform(train_df[TEXT_COL])\n",
    "    test_tfidf = tfidf.transform(test_df[TEXT_COL])\n",
    "\n",
    "    svd = TruncatedSVD(n_components=SVD_DIM, random_state=42)\n",
    "    train_svd = svd.fit_transform(train_tfidf)\n",
    "    test_svd = svd.transform(test_tfidf)\n",
    "\n",
    "    svd_cols = [f\"svd_{i}\" for i in range(SVD_DIM)]\n",
    "\n",
    "    train_df[svd_cols] = pd.DataFrame(train_svd, index=train_df.index, columns=svd_cols)\n",
    "    test_df[svd_cols] = pd.DataFrame(test_svd, index=test_df.index, columns=svd_cols)\n",
    "\n",
    "    print(\"SVD 피처 추가 완료:\", len(svd_cols), \"개\")\n",
    "else:\n",
    "    svd_cols = []\n",
    "    print(\"TF-IDF + SVD 옵션이 꺼져있습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f59f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 7: 최종 피처 구성 및 group 배열 생성 중...\")\n",
    "\n",
    "feature_cols = (\n",
    "    scaled_score_cols\n",
    "    + [\"league_encoded\", \"q_cluster\"]\n",
    "    + pca_cols\n",
    "    + svd_cols\n",
    "    + team_encoded_cols\n",
    ")\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"relevance\"].values\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[\"relevance\"].values\n",
    "\n",
    "# 그룹(질문별 후보 개수)\n",
    "group_train = train_df.groupby(GROUP_COL, sort=False).size().values\n",
    "group_test = test_df.groupby(GROUP_COL, sort=False).size().values\n",
    "\n",
    "categorical_features = [\"league_encoded\", \"q_cluster\"] + team_encoded_cols\n",
    "\n",
    "print(\"피처 수:\", len(feature_cols))\n",
    "print(\"X_train:\", X_train.shape, \" / X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 8: LGBMRanker 학습 시작...\")\n",
    "\n",
    "ranker = lgb.LGBMRanker(**LGB_PARAMS)\n",
    "\n",
    "ranker.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    eval_at=[1, 3, 5],\n",
    "    categorical_feature=categorical_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 9: 성능 평가(질문별 Mean NDCG) 진행 중...\")\n",
    "\n",
    "preds = ranker.predict(X_test)\n",
    "test_df[\"preds\"] = preds\n",
    "\n",
    "ndcg_list = []\n",
    "for q, q_subset in test_df.groupby(GROUP_COL):\n",
    "    if len(q_subset) > 1:\n",
    "        score = ndcg_score([q_subset[\"relevance\"]], [q_subset[\"preds\"]])\n",
    "        ndcg_list.append(score)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 35)\n",
    "print(f\"✅ Mean NDCG: {np.mean(ndcg_list):.4f}\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# (선택) 어떤 피처를 썼는지 확인\n",
    "feature_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 10: GridSearch(수동 루프) 시작...\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) 질문별 Mean NDCG 계산 함수\n",
    "# ------------------------------------------------------------\n",
    "def mean_ndcg_by_group(df_with_pred, group_col=GROUP_COL, y_col=\"relevance\", pred_col=\"preds\"):\n",
    "    \"\"\"\n",
    "    df_with_pred: pred_col(예측점수)가 들어있는 데이터프레임\n",
    "    group_col: 질문 그룹 컬럼명\n",
    "    y_col: 정답 컬럼명 (relevance)\n",
    "    pred_col: 예측점수 컬럼명 (preds)\n",
    "    \"\"\"\n",
    "    ndcg_list = []\n",
    "    \n",
    "    # 질문 단위로 묶어서 NDCG 계산\n",
    "    for q, subset in df_with_pred.groupby(group_col):\n",
    "        # 후보가 2개 이상일 때만 NDCG 의미가 있음\n",
    "        if len(subset) > 1:\n",
    "            score = ndcg_score([subset[y_col]], [subset[pred_col]])\n",
    "            ndcg_list.append(score)\n",
    "    \n",
    "    # 유효 질문이 없으면 0 반환\n",
    "    if len(ndcg_list) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return float(np.mean(ndcg_list))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) 그리드(탐색할 파라미터 후보들) 정의\n",
    "#    - 너무 넓게 잡으면 오래 걸리니까, 초보자는 작게 시작 추천\n",
    "# ------------------------------------------------------------\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"num_leaves\": [15, 31, 63],\n",
    "    \"min_child_samples\": [10, 20, 40],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) 최고 성능 저장 변수\n",
    "# ------------------------------------------------------------\n",
    "best_score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) 조합 개수 계산(대략적인 규모 확인용)\n",
    "# ------------------------------------------------------------\n",
    "total = 1\n",
    "for k, v in param_grid.items():\n",
    "    total *= len(v)\n",
    "print(f\"총 조합 수: {total} (조합이 너무 크면 리스트를 줄여줘!)\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) GridSearch 실행(수동 for-loop)\n",
    "# ------------------------------------------------------------\n",
    "cnt = 0\n",
    "\n",
    "for lr in param_grid[\"learning_rate\"]:\n",
    "    for md in param_grid[\"max_depth\"]:\n",
    "        for ne in param_grid[\"n_estimators\"]:\n",
    "            for nl in param_grid[\"num_leaves\"]:\n",
    "                for mcs in param_grid[\"min_child_samples\"]:\n",
    "                    for ss in param_grid[\"subsample\"]:\n",
    "                        for cs in param_grid[\"colsample_bytree\"]:\n",
    "                            \n",
    "                            cnt += 1\n",
    "                            \n",
    "                            # (1) 모델 생성: 현재 조합으로 파라미터 세팅\n",
    "                            params = dict(LGB_PARAMS)  # 기본 파라미터 복사\n",
    "                            params.update({\n",
    "                                \"learning_rate\": lr,\n",
    "                                \"max_depth\": md,\n",
    "                                \"n_estimators\": ne,\n",
    "                                \"num_leaves\": nl,\n",
    "                                \"min_child_samples\": mcs,\n",
    "                                \"subsample\": ss,\n",
    "                                \"colsample_bytree\": cs,\n",
    "                            })\n",
    "                            \n",
    "                            model = lgb.LGBMRanker(**params)\n",
    "                            \n",
    "                            # (2) 학습: group_train이 반드시 필요\n",
    "                            model.fit(\n",
    "                                X_train, y_train,\n",
    "                                group=group_train,\n",
    "                                categorical_feature=categorical_features,\n",
    "                            )\n",
    "                            \n",
    "                            # (3) 예측\n",
    "                            preds = model.predict(X_test)\n",
    "                            \n",
    "                            # (4) 평가를 위해 test_df 복사본에 preds 저장\n",
    "                            tmp = test_df[[GROUP_COL, \"relevance\"]].copy()\n",
    "                            tmp[\"preds\"] = preds\n",
    "                            \n",
    "                            # (5) 질문별 Mean NDCG 계산\n",
    "                            score = mean_ndcg_by_group(tmp, group_col=GROUP_COL, y_col=\"relevance\", pred_col=\"preds\")\n",
    "                            \n",
    "                            # (6) 진행 로그(너무 많으면 print 줄여도 됨)\n",
    "                            print(f\"[{cnt}/{total}] lr={lr}, md={md}, ne={ne}, leaves={nl}, mcs={mcs}, ss={ss}, cs={cs} -> MeanNDCG={score:.4f}\")\n",
    "                            \n",
    "                            # (7) 최고 성능 갱신\n",
    "                            if score > best_score:\n",
    "                                best_score = score\n",
    "                                best_params = params\n",
    "                                best_model = model\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"✅ Best Mean NDCG: {best_score:.4f}\")\n",
    "print(\"✅ Best Params:\")\n",
    "for k, v in best_params.items():\n",
    "    # 너무 길어지는 파라미터는 기본값이 많으니 핵심만 보고 싶으면 여기 필터링 가능\n",
    "    print(f\"  - {k}: {v}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 11: Best 모델 최종 평가...\")\n",
    "\n",
    "# best_model이 이미 X_train으로 학습된 상태지만,\n",
    "# 혹시 모르니 best_params로 새로 만들고 다시 학습하는 방식(재현성 좋음)\n",
    "final_model = lgb.LGBMRanker(**best_params)\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    categorical_feature=categorical_features,\n",
    ")\n",
    "\n",
    "final_preds = final_model.predict(X_test)\n",
    "\n",
    "final_tmp = test_df[[GROUP_COL, \"relevance\"]].copy()\n",
    "final_tmp[\"preds\"] = final_preds\n",
    "\n",
    "final_score = mean_ndcg_by_group(final_tmp, group_col=GROUP_COL, y_col=\"relevance\", pred_col=\"preds\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"✅ 최종 Best Mean NDCG: {final_score:.4f}\")\n",
    "print(\"=\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
